<!DOCTYPE html>
<html lang="en">





<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/favicon.png">
  <link rel="icon" type="image/png" href="/img/favicon.png">
  <meta name="viewport"
        content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="description" content="">
  <meta name="author" content="JPZhuang">
  <meta name="keywords" content="">
  <title>统计场 - JPZ</title>

  <link  rel="stylesheet" href="https://cdn.staticfile.org/twitter-bootstrap/4.4.1/css/bootstrap.min.css" />


  <link  rel="stylesheet" href="https://cdn.staticfile.org/github-markdown-css/4.0.0/github-markdown.min.css" />
  <link  rel="stylesheet" href="/lib/hint/hint.min.css" />

  
    
    <link  rel="stylesheet" href="https://cdn.staticfile.org/highlight.js/10.0.0/styles/github-gist.min.css" />
  

  


<!-- 主题依赖的图标库，不要自行修改 -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_yg9cfy8wd6.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_pjno9b9zyxs.css">


<link  rel="stylesheet" href="/css/main.css" />

<!-- 自定义样式保持在最底部 -->


  <script  src="/js/utils.js" ></script>
<meta name="generator" content="Hexo 4.2.1"><!-- hexo-inject:begin --><!-- hexo-inject:end --></head>


<body>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><header style="height: 70vh;">
    <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand"
       href="/">&nbsp;<strong>Physics</strong>&nbsp;</a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                Home
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                Archives
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                Categories
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                Tags
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                About
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" data-toggle="modal" data-target="#modalSearch">&nbsp;&nbsp;<i
                class="iconfont icon-search"></i>&nbsp;&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

    <div class="banner intro-2" id="background" parallax=true
         style="background: url('/img/tag-bg.jpg') no-repeat center center;
           background-size: cover;">
      <div class="full-bg-img">
        <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
          <div class="container text-center white-text fade-in-up">
            <span class="h2" id="subtitle">
              
            </span>

            
              
  <div class="mt-3 post-meta">
    <i class="iconfont icon-date-fill" aria-hidden="true"></i>
    <time datetime="2021-02-24 14:23">
      February 24, 2021 pm
    </time>
  </div>


<div class="mt-1">
  
    
    <span class="post-meta mr-2">
      <i class="iconfont icon-chart"></i>
      11.7k 字
    </span>
  

  
    
    <span class="post-meta mr-2">
      <i class="iconfont icon-clock-fill"></i>
      
      
      234
       分钟
    </span>
  

  
  
</div>

            
          </div>

          
        </div>
      </div>
    </div>
  </header>

  <main>
    
      

<div class="container-fluid">
  <div class="row">
    <div class="d-none d-lg-block col-lg-2"></div>
    <div class="col-lg-8 nopadding-md">
      <div class="container nopadding-md" id="board-ctn">
        <div class="py-5" id="board">
          <div class="post-content mx-auto" id="post">
            
            <article class="markdown-body">
              <h2 id="参考">参考</h2>
<ul>
<li>《Statistical Physics of Fields》Kardar</li>
</ul>
<p>[TOC]</p>
<h2 id="statistical-fieldss">2 Statistical fieldss</h2>
<p>We noted in the previous chapter that the singular behavior of thermodynamic functions at a critical point (the termination of a coexistence line) can be characterized by a set of critical exponents <span class="math inline">\(\{\alpha, \beta, \gamma, \cdots\} .\)</span> Experimental observations indicate that these exponents are quite universal, i.e. independent of the material under investigation, and to some extent, of the nature of the phase transition. For example, the vanishing of the coexistence boundary in the condensation of <span class="math inline">\(CO _{2}\)</span> has the same singular behavior as that of the phase separation of protein solutions into dilute and dense components. This universality of behavior needs to be explained. We also noted that the divergence of the response functions, as well as direct observations of fluctuations via scattering studies, indicate that fluctuations have long wavelengths in the vicinity of the critical point, and are correlated over distances <span class="math inline">\(\xi \gg a,\)</span> where <span class="math inline">\(a\)</span> is a typical interparticle spacing. Such correlated fluctuations involve many particles and a coarse-graining approach, in the spirit of the theory of elasticity, may be appropriate to their description. Here we shall construct such a statistical field theory.</p>
<p>We shall frame the discussion in the language of a magnetic system whose symmetries are more transparent, although the results are of more general applicability. Consider a material such as iron, which is experimentally observed to be ferromagnetic below a Curie temperature <span class="math inline">\(T_{c},\)</span> as in Fig. <span class="math inline">\(1.4 .\)</span> The microscopic origin of magnetism is quantum mechanical, involving such elements as itinerant electrons, their spins, and their interactions, described by a microscopic Hamiltonian <span class="math inline">\(H _{\text {mic }}\)</span>. In principle, all thermodynamic properties of the system can be extracted from a partition function obtained by summing over all degrees of freedom, written symbolically as <span class="math display">\[
Z(T)=\operatorname{tr}\left[e^{-\beta H _{\text {mic }}}\right], \quad \text { with } \quad \beta=\frac{1}{k_{ B } T}
\]</span> In practice, this formula is not of much use, as the microscopic Hamiltonian, and degrees of freedom, are too complicated to make a calculation possible. A microscopic theory is certainly necessary to find out which elements are likely to produce ferromagnetism. However, given that there is magnetic behavior, such a theory is not necessarily useful to describe the disappearance of magnetization as a result of thermal fluctuations. For addressing the latter, the (quantum) statistical mechanics of the collection of interacting electrons is an excessively complicated starting point. Instead, we make the observation that the important degrees of freedom close to the Curie point are long wavelength collective excitations of spins (much like the long wavelength phonons that dominate the heat capacity of solids at low temperatures). It thus makes more sense to focus on the statistical properties of these fluctuations which are ultimately responsible for the phase transition. Towards this end, we change focus from the microscopic scales to intermediate mesoscopic scales which are much larger than the lattice spacing, but much smaller than the system size. In a manner similar to the coarse graining process depicted in Fig. <span class="math inline">\(1.1,\)</span> we define a magnetization field <span class="math inline">\(\vec{m}( x ),\)</span> which represents the average of the elemental spins in the vicinity of a point <span class="math inline">\(x .\)</span> It is important to emphasize that while <span class="math inline">\(x\)</span> is treated as a continuous variable, the function <span class="math inline">\(\vec{m}( x )\)</span> does not exhibit any variations at distances of the order of the lattice spacing, i.e. its Fourier transform involves only wavevectors less than some upper cutoff <span class="math inline">\(\Lambda \sim 1 / a\)</span>.</p>
<p>The transformation from the original degrees of freedom to the field <span class="math inline">\(\vec{m}( x )\)</span> is a change of variables. (This mapping is not invertible, as many microscopic details are washed out in the averaging process.) Again, it is in principle possible to obtain the corresponding probabilities for configurations of the field <span class="math inline">\(\vec{m}( x ),\)</span> by transforming the original microscopic probabilities arising from the Boltzmann weight <span class="math inline">\(e ^{-\beta H _{\text {mic }}}\)</span>. The partition function is preserved in the process, and can be written as <span class="math display">\[
Z(T)=\operatorname{tr}\left[ e ^{-\beta H _{ mic }}\right] \equiv \int D \vec{m}( x ) W [\vec{m}( x )]
\]</span> The symbol <span class="math inline">\(D \vec{m}( x )\)</span> indicates integrating over all allowed configurations of the field, and will be discussed later. The different configurations of the field are weighted with a probability <span class="math inline">\(W [\vec{m}( x )],\)</span> which is what we would like to find out.</p>
<p>While obtaining the precise form of <span class="math inline">\(W [\vec{m}( x )]\)</span> is not easier than solving the full problem, it is in fact possible to describe it in terms of a few phenomenological parameters. (This is similar to describing the energy cost of deforming a solid in terms of a few elastic moduli.) In the context of phase transitions, this approach was first applied by Landau to describe the onset of superfluidity in helium. In fact, the method can quite generally be applied to different types of systems undergoing phase transition, with <span class="math inline">\(\vec{m}( x )\)</span> describing the corresponding order parameter field. We shall thus generalize the problem, and consider an <span class="math inline">\(n\)</span> -component field, existing in <span class="math inline">\(d\)</span> -dimensional space, i.e. <span class="math display">\[
\begin{aligned}
&amp;x \equiv\left(x_{1}, x_{2}, \ldots, x_{d}\right) \in R ^{d} \quad(\text { space }), \quad \vec{m} \equiv\left(m_{1}, m_{2}, \ldots, m_{n}\right) \in R ^{n}\\
&amp;\text { (order parameter). }
\end{aligned}
\]</span> Some specific cases covered in this general framework are:</p>
<ul>
<li><span class="math inline">\(n=1\)</span> describes liquid-gas transitions, binary mixtures, as well as uniaxial magnets;</li>
<li><span class="math inline">\(n=2\)</span> applies to superfluidity, superconductivity, and planar magnets;</li>
<li><span class="math inline">\(n=3\)</span> corresponds to classical magnets.</li>
</ul>
<p>While most physical situations occur in three-dimensional space <span class="math inline">\((d=3),\)</span> there are also important phenomena on surfaces <span class="math inline">\((d=2),\)</span> and in wires <span class="math inline">\((d=1)\)</span>. Relativistic field theory is described by a similar structure, but in <span class="math inline">\(d=4\)</span></p>
<h2 id="the-landau-ginzburg-hamiltonian">The Landau-Ginzburg Hamiltonian</h2>
<p>Using the coarse-grained weight in Eq. <span class="math inline">\(2.2,\)</span> we can define an effective Hamiltonian <span class="math display">\[
\beta H [\vec{m}( x )] \equiv-\ln W [\vec{m}( x )]
\]</span> which gives the probabilities of the field configurations by a Boltzmann factor. Guided by the steps outlined in the last chapter for generating the elastic theory of a deformed solid, we shall construct <span class="math inline">\(\beta H [\vec{m}( x )]\)</span> using the following principles:</p>
<h4 id="locality-and-uniformity">Locality and uniformity:</h4>
<p>If a system consists of disconnected parts, the overall probability is obtained as a product of independent probabilities. A corresponding Hamiltonian as in Eq. (2.3) then decomposes into a sum of contributions from each location, going over to an integral in the continuum representation, i.e. <span class="math display">\[
\beta H =\int d ^{d} x \Phi[\vec{m}( x ), x ]
\]</span> Here, <span class="math inline">\(\Phi\)</span> is an energy density, which can in principle have a different functional form at different locations. For a material that is uniform in space, different positions in <span class="math inline">\(x\)</span> are equivalent, and we can drop the explicit dependence of <span class="math inline">\(\Phi\)</span> on <span class="math inline">\(x .\)</span> This will not be the case when the system is in an external potential, or has internal impurities. We are of course interested in more complicated systems in which, as a result of interactions, there is some coupling between different parts of the system. To this end, we generalize Eq. <span class="math inline">\((2.4),\)</span> by including gradients of the field, to <span class="math display">\[
\beta H =\int d ^{d} x \Phi\left[\vec{m}( x ), \nabla \vec{m}, \nabla^{2} \vec{m}, \cdots\right]
\]</span> Once more, general non-local interactions can be described by including many derivatives. The "local" representation is useful when a good description can be obtained by including only a few derivatives. This is the case for short-range interactions (even including van der Waals interactions in liquid gas mixtures, but fails for long-range (such as Coulomb) interactions.</p>
<h4 id="analyticity-and-polynomial-expansions">Analyticity and polynomial expansions:</h4>
<p>The functional form of <span class="math inline">\(\Phi\)</span> is next written as an expansion in powers of <span class="math inline">\(\vec{m},\)</span> and its gradients. To justify such an expansion, let us again examine the simple example of a collection of independent degrees of freedom, say spins. The probability distribution at the microscopic level may be complicated; e.g. spins may be constrained to a fixed magnitude, or quantized to specific values. At the mesoscopic scale, the field <span class="math inline">\(\vec{m}\)</span> is obtained by averaging many such spins. The averaging process typically simplifies the probability distribution; in most cases the central limit theorem implies that the probability distribution for the sum approaches a Gaussian form. <span class="math inline">\(^{2}\)</span> In constructing the statistical field theory, we are in fact searching for generalizations of the central limit theorem for describing interacting degrees of freedom. The key point is that in going from the microscopic to mesoscopic scales, non-analyticities associated with the microscopic degrees of freedom are washed out, and the probability distribution for the coarsegrained field is obtained by an analytic expansion in powers of <span class="math inline">\(\vec{m}\)</span>. There are of course non-analyticities associated with the phase transition at the macroscopic scale. However, such singularities involve an infinity (macroscopic number) of degrees of freedom. By focusing on the mesoscopic scale we thus avoid possible singularities at both the short and long scales!</p>
<h4 id="symmetries">Symmetries:</h4>
<p>One element that survives the averaging process is any underlying microscopic symmetry. Such symmetries in turn constrain possible forms and expansions of the effective Hamiltonian. For example, in the absence of an external magnetic field, all directions for magnetization are equivalent, and hence <span class="math inline">\(H \left[R_{n} \vec{m}( x )\right]= H [\vec{m}( x )],\)</span> where <span class="math inline">\(R_{n}\)</span> is a rotation in the <span class="math inline">\(n\)</span> -dimensional order parameter space. A linear term in <span class="math inline">\(\vec{m}\)</span> is not consistent with this symmetry, and the first term in an expansion is proportional to <span class="math display">\[
m^{2}( x ) \equiv \vec{m}( x ) \cdot \vec{m}( x ) \equiv \sum_{i=1}^{n} m_{i}( x ) m_{i}( x )
\]</span> where <span class="math inline">\(\left\{m_{i}\right\}\)</span> indicate the components of the vector field. Higher order terms in the series are constructed from <span class="math display">\[
m^{4}( x ) \equiv\left(m^{2}( x )\right)^{2}, \quad m^{6}( x ) \equiv\left(m^{2}( x )\right)^{3}, \quad \cdots
\]</span> In constructing terms that involve gradients of the vector field, we should keep in mind the spatial symmetries of the system. In an isotropic system all directions in space are equivalent, and we should use combinations of derivatives that are invariant under spatial rotations. The simplest such term is <span class="math display">\[
(\nabla \vec{m})^{2} \equiv \sum_{i=1}^{n} \sum_{\alpha=1}^{d} \partial_{\alpha} m_{i} \partial_{\alpha} m_{i}
\]</span> with <span class="math inline">\(\partial_{\alpha}\)</span> indicating the partial derivative along the <span class="math inline">\(\alpha\)</span> -th direction in space. If the different directions are not equivalent more terms are allowed. For example, in a two dimensional magnet on a rectangular lattice (unit cell aligned with the axes), the coefficients of <span class="math inline">\(\partial_{1} m_{i} \partial_{1} m_{i}\)</span> and <span class="math inline">\(\partial_{2} m_{i} \partial_{2} m_{i}\)</span> can be different. However, by appropriate rescaling of coordinates the leading gradient term can again be changed into the form of Eq. <span class="math inline">\((2.7) .\)</span> A fourth order gradient term in an isotropic system is <span class="math display">\[
\left(\nabla^{2} \vec{m}\right)^{2} \equiv \sum_{i=1}^{n} \sum_{\alpha=1}^{d} \sum_{\beta=1}^{d}\left(\partial_{\alpha} \partial_{\alpha} m_{i}\right)\left(\partial_{\beta} \partial_{\beta} m_{i}\right)
\]</span> and a possible quartic term in <span class="math inline">\(\vec{m}\)</span> is <span class="math display">\[
m^{2}(\nabla \vec{m})^{2} \equiv \sum_{i=1}^{n} \sum_{j=1}^{n} \sum_{\alpha=1}^{d} m_{i} m_{i} \partial_{\alpha} m_{j} \partial_{\alpha} m_{j}
\]</span> Anisotropies again lead to higher order terms which in general cannot be removed by simple rescalings.</p>
<p>We shall demonstrate shortly that to describe magnetic systems, and in fact most transitions, it is sufficient to include only a few terms, leading to the so called Landau-Ginzburg Hamiltonian: <span class="math display">\[
\beta H =\beta F_{0}+\int d ^{d} x \left[\frac{t}{2} m^{2}( x )+u m^{4}( x )+\frac{K}{2}(\nabla m)^{2}+\cdots-\vec{h} \cdot \vec{m}( x )\right]
\]</span> The integration over the magnetic and non-magnetic degrees of freedom at short scales also generates an overall constant <span class="math inline">\(\beta F_{0} .\)</span> This contribution to the overall free energy is analytic (as discussed earlier), and will be mostly ignored. Equation (2.8) also includes the contribution from the magnetic work <span class="math inline">\(\vec{B} \cdot \vec{m}\)</span> to the Hamiltonian, where <span class="math inline">\(\vec{h} \equiv \beta \vec{B}\)</span> and <span class="math inline">\(\vec{B}\)</span> is the magnetic field. <span class="math inline">\(^{3}\)</span> The magnetic field may also generate higher order terms, such as <span class="math inline">\(m^{2} \vec{m} \cdot \vec{h},\)</span> which are less important than the terms explicitly included above.</p>
<h4 id="stability">Stability:</h4>
<p>Since it originates from a well defined physical problem, the coarsegrained Boltzmann weight must not lead to any unphysical field configurations. In particular, the probability should not diverge for infinitely large values of <span class="math inline">\(\vec{m}\)</span>. This condition implies that the coefficient of the highest order power of <span class="math inline">\(\vec{m},\)</span> e.g. the parameter <span class="math inline">\(u\)</span> in Eq. (2.8), should be positive. There are related constraints on the signs of the terms involving gradients to avoid oscillatory instabilities.</p>
<p>The Landau-Ginzburg Hamiltonian depends on a set of phenomenological parameters <span class="math inline">\(\{t, u, K, \cdots\} .\)</span> These parameters are non-universal functions of microscopic interactions, as well as external parameters such as temperature and pressure. It is essential to fully appreciate the latter point which is a possible source of confusion. While the probability for a particular configuration of the field is given by the Boltzmann weight <span class="math inline">\(\exp \{-\beta H [\vec{m}( x )]\},\)</span> this does not imply that all terms in the exponent are proportional to <span class="math inline">\(\left(k_{ B } T\right)^{-1}\)</span>. Such dependence holds only for the true microscopic Hamiltonian. The Landau-Ginzburg Hamiltonian is more correctly an effective free energy obtained by integrating over (coarse graining) the microscopic degrees of freedom, while constraining their average to <span class="math inline">\(\vec{m}( x ) .\)</span> It is precisely because of the difficulty of carrying out such a first principles program that we postulate the form of the resulting effective free energy on the basis of symmetries alone. The price paid is that the phenomenological parameters have unknown functional dependences on the original microscopic parameters, as well as on such external constraints as temperature (since we have to account for the entropy of the short distance fluctuations lost in the coarse-graining process). The constraints on these functional forms again arise from symmetry, analyticity, and stability, as discussed in the context of constructing the function form of <span class="math inline">\(\Phi[\vec{m}] .\)</span> Notably, these mesoscopic coefficients will be analytic functions of the external parameters, e.g. expressible as power series in temperature <span class="math inline">\(T\)</span>.</p>
<h2 id="saddle-point-approximation-and-mean-field-theory">Saddle point approximation, and mean-field theory</h2>
<p>By focusing only on the coarse-grained magnetization field, we have considerably simplified the original problem. Various thermodynamic functions (and their singular behavior) should now be obtained from the partition function <span class="math display">\[
Z=\int D \vec{m}( x ) \exp \{-\beta H [\vec{m}( x )]\}
\]</span> corresponding to the Landau-Ginzburg Hamiltonian in Eq. (2.8). The degrees of freedom appearing in the Hamiltonian are functions of <span class="math inline">\(x ,\)</span> the symbol <span class="math inline">\(\int D \vec{m}( x )\)</span> refers to a functional integral. In practice, the functional integral is obtained as a limit of discrete integrals: The continuous coordinate <span class="math inline">\(x \equiv\left(x_{1}, x_{2}, \cdots x_{d}\right)\)</span> is first discretized into a lattice of <span class="math inline">\(N\)</span> points <span class="math inline">\(i \equiv\left(i_{1}, i_{2}, \cdots i_{d}\right),\)</span> at a lattice distance <span class="math inline">\(a ;\)</span> the various derivatives are replaced with appropriate differences, and the functional integral is obtained as <span class="math display">\[
\int D \vec{m}( x ) F \left[\vec{m}( x ), \frac{\partial \vec{m}}{\partial x_{\alpha}}, \cdots\right] \equiv \lim _{ N \rightarrow \infty} \prod_{i=1}^{ N } d \vec{m}_{i} F \left[\vec{m}_{i}, \frac{\vec{m}_{i_{\alpha}+1}-\vec{m}_{i_{\alpha}}}{a}, \cdots\right]
\]</span> There are in fact many mathematical concerns regarding the existence of functional integrals. These problems are mostly associated with having too many degrees of freedom at short distances, which allow for rather badly behaved functions. These issues need not concern us since we know that the underlying problem has a well defined lattice spacing that restricts and controls the short distance behavior.</p>
<p>Even after all these simplifications, it is still not easy to calculate the Landau-Ginzburg partition function in Eq. (2.9). As a first step, we perform a saddle point approximation in which the integral in Eq. (2.9) is replaced by the maximum value of the integrand, corresponding to the most probable configuration of the field <span class="math inline">\(\vec{m}( x ) .\)</span> The natural tendency of interactions in a magnet is to keep the magnetizations vectors parallel, and hence we expect the parameter <span class="math inline">\(K\)</span> in Eq. (2.8) to be positive. <span class="math inline">\({ }^{4}\)</span> Any variations in magnitude or direction of <span class="math inline">\(\vec{m}( x )\)</span> incur an "energy penalty" from the term <span class="math inline">\(K(\nabla \vec{m})^{2}\)</span> in Eq. (2.8) . Thus the field is uniform in its most probable configuration, and restricting the integration to this subspace gives <span class="math display">\[
Z \approx Z_{ sp }= e ^{-\beta F_{0}} \int d \vec{m} \exp \left[-V\left(\frac{t}{2} m^{2}+u m^{4}+\cdots-\vec{h} \cdot \vec{m}\right)\right]
\]</span> where <span class="math inline">\(V\)</span> is the system volume. In the limit of <span class="math inline">\(V \rightarrow \infty\)</span> the integral is governed by the saddle point <span class="math inline">\(\vec{m},\)</span> which maximizes the exponent of the integrand. The corresponding saddle point free energy is <span class="math display">\[
\beta F_{ sp }=-\ln Z_{ sp } \approx \beta F_{0}+V \min \{\Psi(\vec{m})\}_{\vec{m}}
\]</span> where <span class="math display">\[
\Psi(\vec{m}) \equiv \frac{t}{2} \vec{m}^{2}+u\left(\vec{m}^{2}\right)^{2}+\cdots-\vec{h} \cdot \vec{m}
\]</span> where <span class="math inline">\(V\)</span> is the system volume. In the limit of <span class="math inline">\(V \rightarrow \infty\)</span> the integral is governed by the saddle point <span class="math inline">\(\vec{m},\)</span> which maximizes the exponent of the integrand. The corresponding saddle point free energy is <span class="math display">\[
\beta F_{ sp }=-\ln Z_{ sp } \approx \beta F_{0}+V \min \{\Psi(\vec{m})\}_{\vec{m}}
\]</span> where <span class="math display">\[
\Psi(\vec{m}) \equiv \frac{t}{2} \vec{m}^{2}+u\left(\vec{m}^{2}\right)^{2}+\cdots-\vec{h} \cdot \vec{m}
\]</span> The most likely magnetization will be aligned to the external field, i.e. <span class="math inline">\(\vec{m}( x )=\)</span> <span class="math inline">\(\bar{m} \hat{h}\)</span>; its magnitude is obtained from <span class="math display">\[
\Psi^{\prime}(\bar{m})=t \bar{m}+4 u \bar{m}^{3}+\cdots-h=0
\]</span> Surprisingly, this simple equation captures the qualitative behavior at a phase transition.</p>
<p>While the function <span class="math inline">\(\Psi(m)\)</span> is analytic, and has no singularities, the saddle point free energy is Eq. (2.11) may well be non-analytic. This is because the minimization operation is not an analytic procedure, and introduces singularities as we shall shortly demonstrate. What justifies the saddle point evaluation of Eq. (2.10) is the thermodynamic limit of <span class="math inline">\(V \rightarrow \infty,\)</span> and for finite <span class="math inline">\(V,\)</span> the integral is perfectly analytic. In the vicinity of the critical point, the magnetization is small, and it is justified to keep only the lowest powers in the expansion of <span class="math inline">\(\Psi(\vec{m})\)</span>. (We can later check self-consistently that the terms left out of the expansion are indeed small corrections.) The behavior of <span class="math inline">\(\Psi(m)\)</span> depends strongly on the sign of the parameter <span class="math inline">\(t\)</span>.</p>
<ul>
<li><ol type="1">
<li>For <span class="math inline">\(t&gt;0,\)</span> the quartic term is not necessary for stability and can be ignored. The solution to Eq. (2.13) is <span class="math inline">\(\bar{m}=h / t,\)</span> and describes paramagnetic behavior. The most probable magnetization is aligned to the magnetic field, and vanishes continuously as <span class="math inline">\(\vec{h} \rightarrow 0 .\)</span> The susceptibility <span class="math inline">\(\chi=1 / t,\)</span> diverges as <span class="math inline">\(t \rightarrow 0\)</span></li>
</ol></li>
<li><ol start="2" type="1">
<li>For <span class="math inline">\(t&lt;0\)</span>, a quartic term with a positive value of <span class="math inline">\(u\)</span> is required to insure stability (i.e. a finite magnetization). The function <span class="math inline">\(\Psi(m)\)</span> can now have two local minima, the global minimum being aligned with the field <span class="math inline">\(\vec{h}\)</span>. As <span class="math inline">\(\vec{h} \rightarrow 0,\)</span> the global minimum moves towards a non-zero value, indicating a spontaneous magnetization, even at <span class="math inline">\(\vec{h}=0,\)</span> as in a ferromagnet. The direction of <span class="math inline">\(\vec{m}\)</span> at <span class="math inline">\(\vec{h}=0\)</span> is determined by the system's history, and can be realigned by an external field <span class="math inline">\(\vec{h}\)</span>.</li>
</ol>
The resulting curves for the most probable magnetization <span class="math inline">\(\bar{m}(h)\)</span> are quite similar to those of Fig. 1.4 . The saddle point evaluation of the Landau-Ginzburg partition function thus results in paramagnetic behavior for <span class="math inline">\(t&gt;0,\)</span> and ferromagnetic behavior for <span class="math inline">\(t&lt;0,\)</span> with a line of phase transitions terminating at the point <span class="math inline">\(t=h=0\)</span>.</li>
</ul>
<p>As noted earlier, the parameters <span class="math inline">\((t, u, K, \cdots)\)</span> of the Landau-Ginzburg Hamiltonian are analytic functions of temperature, and can be expanded around the critical point at <span class="math inline">\(T=T_{c}\)</span> in a Taylor series as <span class="math display">\[
\left\{\begin{array}{l}
t(T, \cdots)=a_{0}+a_{1}\left(T-T_{c}\right)+ O \left(T-T_{c}\right)^{2} \\
u(T, \cdots)=u+u_{1}\left(T-T_{c}\right)+ O \left(T-T_{c}\right)^{2} \\
K(T, \cdots)=K+K_{1}\left(T-T_{c}\right)+ O \left(T-T_{c}\right)^{2}
\end{array}\right.
\]</span> The expansion coefficients can be regarded as phenomenological parameters which can be determined by comparing to experiments. In particular, matching the phase diagrams in Figs. 1.4 and 2.3 requires that <span class="math inline">\(t\)</span> should be a monotonic function of temperature which vanishes at <span class="math inline">\(T_{c},\)</span> necessitating <span class="math inline">\(a_{0}=0\)</span> and <span class="math inline">\(a_{1}=\)</span> <span class="math inline">\(a&gt;0 .\)</span> Stability of the ferromagnetic phase in the vicinity of the critical point requires that <span class="math inline">\(u\)</span> and <span class="math inline">\(K\)</span> should be positive. The minimal set of conditions for matching the experimental phase diagram of a magnet to that obtained from the saddle point is <span class="math display">\[
t=a\left(T-T_{c}\right)+ O \left(T-T_{c}\right)^{2}, \quad \text { with } \quad(a, u, K)&gt;0
\]</span> It is of course possible to set additional terms in the expansion, e.g. <span class="math inline">\(a\)</span> or <span class="math inline">\(u\)</span> to zero, and maintain the phase diagram and stability by appropriate choice of the higher order terms. However, such choices are not generic, and there is no reason for imposing more constraints than absolutely required by the experiment.</p>
<p>Using Eq. (2.15), we can quantify the singular behaviors predicted by the saddle point evaluations of the free energy in Eqs. <span class="math inline">\((2.11)-(2.13) .\)</span></p>
<h4 id="magnetization">Magnetization</h4>
<p>In zero field, Eq. (2.13) reduces to <span class="math inline">\(\partial \Psi / \partial m=t \bar{m}+4 u \bar{m}^{3}=\bar{m}(t+\)</span> <span class="math inline">\(\left.4 u \bar{m}^{2}\right)=0,\)</span> and we obtain <span class="math display">\[
\bar{m}(h=0)=\left\{\begin{array}{ll}
0 &amp; \text { for } t&gt;0 \\
\sqrt{\frac{-t}{4 u}}=\sqrt{\frac{a}{4 u}}\left(T_{c}-T\right)^{1 / 2} &amp; \text { for } t&lt;0
\end{array}\right.
\]</span> For <span class="math inline">\(t&lt;0\)</span>, the non-magnetized solution <span class="math inline">\(\bar{m}=0\)</span> is a maximum of <span class="math inline">\(\Psi(m),\)</span> and there is a spontaneous magnetization that vanishes with a universal exponent of <span class="math inline">\(\beta=1 / 2\)</span>. The overall amplitude is non-universal and material dependent.</p>
<p>Along the critical isotherm (the dashed line of Fig. 2.3), with <span class="math inline">\(t=0,\)</span> Eq. (2.13) gives <span class="math display">\[
\bar{m}(t=0)=\left(\frac{h}{4 u}\right)^{1 / 3}
\]</span> i.e. <span class="math inline">\(h \propto \bar{m}^{\delta},\)</span> with an exponent <span class="math inline">\(\delta=3\)</span>.</p>
<h4 id="susceptibility">Susceptibility:</h4>
<p>The magnetization is aligned to the external field, <span class="math inline">\(\vec{m}=\bar{m}(h) \hat{h},\)</span> its magnitude given by the solution to <span class="math inline">\(t \bar{m}+4 u \bar{m}^{3}=h .\)</span> The changes in the magnitude are governed by the longitudinal susceptibility <span class="math inline">\(\chi_{\ell},\)</span> whose inverse is easily obtained as <span class="math display">\[
\chi_{\ell}^{-1}=\left.\frac{\partial h}{\partial m}\right|_{h=0}=t+12 u \bar{m}^{2}=\left\{\begin{array}{ll}
t &amp; \text { for } t&gt;0, \text { and } h=0 \\
-2 t &amp; \text { for } t&lt;0, \text { and } h=0
\end{array}\right.
\]</span> On approaching the critical point from either side, the zero field susceptibility diverges as <span class="math inline">\(\chi_{\pm} \sim A_{\pm}|t|^{-\gamma_{\pm}},\)</span> with <span class="math inline">\(\gamma_{+}=\gamma_{-}=1 .\)</span> Although the amplitudes <span class="math inline">\(A_{\pm}\)</span> are material dependent, Eq. (2.18) predicts that their ratio is universal, given by <span class="math inline">\(A_{+} / A_{-}=2 .\)</span> (We shall shortly encounter the transverse susceptibility <span class="math inline">\(\chi_{t},\)</span> which describes the change in magnetization in response to a field perpendicular to it. For <span class="math inline">\(h=0, \chi_{t}\)</span> is always infinite in the magnetized phase.)</p>
<h4 id="heat-capacity">Heat capacity:</h4>
<p>The free energy for <span class="math inline">\(h=0\)</span> is given by <span class="math display">\[
\beta F=\beta F_{0}+V \Psi(\bar{m})=\beta F_{0}+V\left\{\begin{array}{ll}
0 &amp; \text { for } t&gt;0 \\
-\frac{t^{2}}{16 u} &amp; \text { for } t&lt;0 .
\end{array}\right.
\]</span> Since <span class="math inline">\(t=a\left(T-T_{c}\right)+\cdots,\)</span> to leading order in <span class="math inline">\(\left(T-T_{c}\right),\)</span> we have <span class="math inline">\(\partial / \partial T \sim a \partial / \partial t .\)</span> Using similar approximations in the vicinity of the critical point, we find the behavior of the heat capacity at zero field as <span class="math display">\[
C(h=0)=-T \frac{\partial^{2} F}{\partial T^{2}} \approx-T_{c} a^{2} \frac{\partial^{2}}{\partial t^{2}}\left(k_{ B } T_{c} \beta F\right)=C_{0}+V k_{ B } a^{2} T_{c}^{2} \times\left\{\begin{array}{ll}
0 &amp; \text { for } t&gt;0 \\
\frac{1}{8 u} &amp; \text { for } t&lt;0
\end{array}\right.
\]</span> The saddle point method thus predicts a discontinuity, rather than a divergence, in the heat capacity. If we insist on describing this singularity as a power law <span class="math inline">\(t^{-\alpha},\)</span> we have to choose the exponent <span class="math inline">\(\alpha=0\)</span></p>
<h2 id="continuous-symmetry-breaking-and-goldstone-modes">Continuous symmetry breaking and Goldstone modes</h2>
<p>For zero field, although the microscopic Hamiltonian has full rotational symmetry, the low-temperature phase does not. As a specific direction in <span class="math inline">\(n\)</span> -space is selected for the net magnetization <span class="math inline">\(\vec{M},\)</span> there is spontaneous symmetry breaking, and a corresponding long-range order is established in which the majority of the spins in the system are oriented along <span class="math inline">\(\vec{M}\)</span>. The original symmetry is still present globally, in the sense that if all local spins are rotated together (i.e. the field transforms as <span class="math inline">\(\vec{m}( x ) \mapsto \Re \vec{m}( x )),\)</span> there is no change in energy. Such a rotation transforms one ordered state into an equivalent one. Since a uniform rotation costs no energy, by continuity we expect a rotation that is slowly varying in space (e.g. <span class="math inline">\(\vec{m}( x ) \mapsto\)</span> <span class="math inline">\(\Re( x ) \vec{m}( x ),\)</span> where <span class="math inline">\(R ( x )\)</span> only has long wavelength variations) to cost very little energy. Such low energy excitations are called Goldstone modes. These collective modes appear in any system with a broken continuous symmetry. <span class="math inline">\(^{5}\)</span> Phonons in a solid provide a familiar example of Goldstone modes, corresponding to the breaking of translation and rotation symmetries by a crystal structure.</p>
<p>The Goldstone modes appearing in diverse systems share certain common characteristics. Let us explore the origin and behavior of Goldstone modes in the context of superfluidity. In analogy to Bose condensation, the superfluid phase has a macroscopic occupation of a single quantum ground state. The order parameter, <span class="math display">\[
\psi( x ) \equiv \psi_{\Re}( x )+i \psi_{3}( x ) \equiv|\psi( x )| e ^{ i \theta( x )}
\]</span> can be roughly regarded as the ground state component (overlap) of the actual wavefunction in the vicinity of <span class="math inline">\(x .{ }^{6}\)</span> The phase of the wavefunction is not an observable quantity and should not appear in any physically measurable probability. This observation constrains the form of the effective coarse grained Hamiltonian, leading to an expansion <span class="math display">\[
\beta H =\beta F_{0}+\int d ^{d} x \left[\frac{K}{2}|\nabla \psi|^{2}+\frac{t}{2}|\psi|^{2}+u|\psi|^{4}+\cdots\right]
\]</span> Equation (2.22) is in fact equivalent to the Landau-Ginzburg Hamiltonian with <span class="math inline">\(n=2,\)</span> as can be seen by changing variables to the two component field <span class="math inline">\(\vec{m}( x ) \equiv\left(\psi_{\Re}( x ), \psi_{\Im}( x )\right) .\)</span> The superfluid transition is signaled by the onset of a finite value of <span class="math inline">\(\psi\)</span> for <span class="math inline">\(t&lt;0 .\)</span> The Landau-Ginzburg Hamiltonian (for a uniform <span class="math inline">\(\psi\)</span> ) has the shape of a wine bottle (or Mexican hat) for <span class="math inline">\(t&lt;0\)</span>.</p>
<p>Minimizing this function sets the magnitude of <span class="math inline">\(\psi,\)</span> but does not fix its phase <span class="math inline">\(\theta .\)</span> Now consider a state with a slowly varying phase, i.e. with <span class="math inline">\(\psi( x )=\bar{\psi} e ^{ i \theta( x )}\)</span> Inserting this form into the Hamiltonian yields an energy <span class="math display">\[
\beta H =\beta H _{0}+\frac{\bar{K}}{2} \int d ^{d} x (\nabla \theta)^{2}
\]</span> where <span class="math inline">\(\bar{K}=K \bar{\psi}^{2}\)</span>. As in the case of phonons we could have guessed the above form by appealing to the invariance of the energy function under a uniform rotation: Since a transformation <span class="math inline">\(\theta( x ) \mapsto \theta( x )+\theta_{0}\)</span> should not change the energy, the energy density can only depend on gradients <span class="math inline">\(\theta( x )\)</span>, and the first term in the expansion leads to Eq. (2.23). The reasoning based on symmetry does not give the value of the stiffness parameter. By starting from the Landau-Ginzburg form which incorporates both the normal and superfluid phases we find that <span class="math inline">\(\bar{K}\)</span> is proportional to the square of the order parameter, and vanishes (softens) at the critical point as <span class="math inline">\(\bar{K} \propto \bar{\psi}^{2} \propto t\)</span> We can decompose the variations in phase of the order parameter into independent normal modes by setting (in a region of volume <span class="math inline">\(V\)</span> ) <span class="math display">\[
\theta( x )=\frac{1}{\sqrt{V}} \sum_{ q } e ^{ i q \cdot x } \theta_{ q }
\]</span> Taking advantage of translational symmetry, Eq. (2.23) then gives <span class="math display">\[
\beta H =\beta H _{0}+\frac{\bar{K}}{2} \sum_{ q } q^{2}|\theta( q )|^{2}
\]</span> We can see that, as in the case of phonons, the energy of a Goldstone mode of wavenumber <span class="math inline">\(q\)</span> is proportional to <span class="math inline">\(q^{2},\)</span> and becomes very small at long wavelengths.</p>
<h2 id="discrete-symmetry-breaking-and-domain-walls">Discrete symmetry breaking and domain walls</h2>
<p>For a one component (scalar) field, there are two possible values for the magnetization in the ordered phase. While the two possible states have the same energy, it is not possible to continuously deform one into the other. In this case, as well as in other systems with discrete symmetry breaking, different states in the same sample are separated by sharp domain walls. To demonstrate this, consider a scalar field with the Landau-Ginzburg Hamiltonian for <span class="math inline">\(t&lt;0\)</span> and <span class="math inline">\(h=0 .\)</span> A domain wall can be introduced by forcing the two sides of the system to be in different states, e.g. by requiring <span class="math inline">\(m(x \rightarrow-\infty)=-\bar{m}\)</span> and <span class="math inline">\(m(x \rightarrow+\infty)=+\bar{m}\)</span>. In between, the most probable field configuration is obtained by minimizing the energy, and satisfies <span class="math display">\[
\frac{ d ^{2} m_{w}(x)}{ d x^{2}}=t m_{w}(x)+4 u m_{w}(x)^{3}
\]</span> By using the identity <span class="math inline">\(d^{2} \tanh (a x) / d x^{2}=a^{2} \tanh (a x)\left[1-\tanh ^{2}(a x)\right],\)</span> it can be easily checked that the profile <span class="math display">\[
m_{w}(x)=\bar{m} \tanh \left[\frac{x-x_{0}}{w}\right]
\]</span> is a solution to the above nonlinear differential equation, provided <span class="math display">\[
w=\sqrt{\frac{2 K}{-t}}, \quad \text { and } \quad \bar{m}=\sqrt{\frac{-t}{4 u}}
\]</span> The above solution separates regions where the magnetization approaches its two possible bulk values of <span class="math inline">\(\pm \bar{m}\)</span>. The domain wall between the two regions is centered at an arbitrary position <span class="math inline">\(x_{0},\)</span> and has a width <span class="math inline">\(w .\)</span> On approaching the phase transition at <span class="math inline">\(t=0\)</span> this width diverges as <span class="math inline">\(\left(T_{c}-T\right)^{-1 / 2} .\)</span> The width <span class="math inline">\(w\)</span> is in fact proportional to the correlation length of the system, which will be calculated in the next chapter.</p>
<p>The free energy cost of creating a domain wall in the system can be obtained by examining the energy difference to a uniformly magnetized solution, as <span class="math display">\[
\begin{aligned}
\beta F_{w} &amp; \equiv \beta F\left[m_{w}(x)\right]-\beta F[\bar{m}] \\
&amp;=\int d ^{d} x \left[\frac{K}{2}\left(\frac{ d m_{w}}{ d x}\right)^{2}+\frac{t}{2}\left(m_{w}^{2}-\bar{m}^{2}\right)+u\left(m_{w}^{4}-\bar{m}^{4}\right)\right]
\end{aligned}
\]</span> Simple algebraic manipulations then give <span class="math display">\[
\beta F_{w}=-\frac{t}{2} \bar{m}^{2} \int d ^{d} x \cosh ^{-4}\left(\frac{x-x_{0}}{w}\right)=-\frac{t}{2} \bar{m}^{2} w A \int_{-\infty}^{\infty} \frac{ d y}{\cosh ^{4} y}=-\frac{2}{3} t \bar{m}^{2} w A
\]</span> where <span class="math inline">\(A\)</span> is the cross-sectional area of the system normal to the <span class="math inline">\(x\)</span> direction. The free energy per unit area is proportional to the bulk energy density, multiplied by the width of the domain wall. On approaching the phase transition, the above calculation predicts that the interfacial free energy vanishes as <span class="math inline">\(\left(T_{c}-T\right)^{3 / 2}\)</span></p>
<h2 id="fluctuations">3 Fluctuations</h2>
<h2 id="scattering-and-fluctuations">Scattering and fluctuations</h2>
<p>In addition to bulk thermodynamic experiments, scattering measurements can be used to probe microscopic fluctuations at length scales of the order of the probe wavelength <span class="math inline">\(\lambda\)</span>. In a typical set up, a beam of wavevector <span class="math inline">\(k _{i}\)</span> is incident upon the sample and the scattered intensity is measured at wavevector <span class="math inline">\(k _{s}=\)</span> <span class="math inline">\(k _{i}+ q .\)</span> For elastic scattering, <span class="math inline">\(\left| k _{i}\right|=\left| k _{s}\right| \equiv k,\)</span> and <span class="math inline">\(q \equiv| q |=2 k \sin \theta,\)</span> where <span class="math inline">\(\theta\)</span> is the angle between incident and scattered beams. Standard treatments of scattering start with the Fermi golden rule, and usually lead to a scattering amplitude of the form <span class="math display">\[
A( q ) \propto\left\langle k _{s} \otimes f| U | k _{i} \otimes i\right\rangle \propto \sigma( q ) \int d ^{d} x e ^{ i q \cdot x } \rho( x )
\]</span> In the above expression, <span class="math inline">\(|i\rangle\)</span> and <span class="math inline">\(|f\rangle\)</span> refer to the initial and final states of the sample, and <span class="math inline">\(U\)</span> is the scattering potential that can be decomposed as a sum due to the various scattering elements in the sample. The amplitude has a local form factor <span class="math inline">\(\sigma( q )\)</span> describing the scattering from an individual element. For our purposes, the more interesting global information is contained in <span class="math inline">\(\rho( q )\)</span>, the Fourier transform of the global density of scatterers <span class="math inline">\(\rho( x ) .\)</span> The appropriate scattering density depends on the nature of the probe. Light scattering senses the actual atomic density, electron scattering measures the charge density, while neutron scattering is usually used to probe the magnetization density. Most such probes actually do not respond to a snapshot of the system, but look at time averaged configurations. Thus the observed scattering intensity is <span class="math display">\[
S( q ) \propto\left\langle|A( q )|^{2}\right\rangle \propto\left\langle|\rho( q )|^{2}\right\rangle
\]</span> Here <span class="math inline">\(\langle\bullet\rangle\)</span> indicates the thermal average of <span class="math inline">\(\bullet,\)</span> which can be used in place of the time average in most cases due to ergodicity.</p>
<p>Equation (3.2) indicates that a uniform density only leads to forward scattering <span class="math inline">\(( q = 0 ),\)</span> while the long-wavelength fluctuations can be studied by working at small angles or with small <span class="math inline">\(k .\)</span> If scattering is caused by the magnetization density, we can use the Landau-Ginzburg Hamiltonian to compute its intensity. The probability of a particular configuration is given by <span class="math display">\[
P [\vec{m}( x )] \propto \exp \left\{-\int d ^{d} x \left[\frac{K}{2}(\nabla m)^{2}+\frac{t}{2} m^{2}+u m^{4}\right]\right\}
\]</span> As discussed earlier, the most probable configuration is uniform, with <span class="math inline">\(\vec{m}( x )=\)</span> <span class="math inline">\(\bar{m} \hat{e}_{1},\)</span> where <span class="math inline">\(\hat{e}_{1}\)</span> is a unit vector <span class="math inline">\((\bar{m}\)</span> is zero for <span class="math inline">\(t&gt;0,\)</span> and equal to <span class="math inline">\(\sqrt{-t / 4 u}\)</span> for <span class="math inline">\(t&lt;0\)</span> ). We can examine small fluctuations around such a configuration by setting <span class="math display">\[
\vec{m}( x )=\left[\bar{m}+\phi_{\ell}( x )\right] \hat{e}_{1}+\sum_{\alpha=2}^{n} \phi_{t, \alpha}( x ) \hat{e}_{\alpha}
\]</span> where <span class="math inline">\(\phi_{\ell}\)</span> and <span class="math inline">\(\phi_{t}\)</span> refer to longitudinal and transverse fluctuations, respectively. The latter can take place along any of the <span class="math inline">\(n-1\)</span> directions perpendicular to the average magnetization.</p>
<p>After the substitution of Eq. (3.4), the terms appearing in the LandauGinzburg Hamiltonian can be expanded to second order as <span class="math display">\[
\begin{aligned}
(\nabla m)^{2} &amp;=\left(\nabla \phi_{\ell}\right)^{2}+\left(\nabla \phi_{t}\right)^{2} \\
m^{2} &amp;=m^{2}+2 m \phi_{\ell}+\phi_{\ell}^{2}+\phi_{t}^{2} \\
m^{4} &amp;=\bar{m}^{4}+4 \bar{m}^{3} \phi_{\ell}+6 \bar{m}^{2} \phi_{\ell}^{2}+2 \bar{m}^{2} \phi_{t}^{2}+ O \left(\phi_{\ell}^{3}, \phi_{t}^{3}\right)
\end{aligned}
\]</span> resulting in a quadratic energy cost <span class="math display">\[
\begin{array}{c}
\beta H \equiv-\ln P =V\left(\frac{t}{2} \bar{m}^{2}+u \bar{m}^{4}\right)+\int d ^{d} x \left[\frac{K}{2}\left(\nabla \phi_{\ell}\right)^{2}+\frac{t+12 u \bar{m}^{2}}{2} \phi_{\ell}^{2}\right] \\
\quad+\int d ^{d} x \left[\frac{K}{2}\left(\nabla \phi_{t}\right)^{2}+\frac{t+4 u \bar{m}^{2}}{2} \phi_{t}^{2}\right]+ O \left(\phi_{\ell}^{3}, \phi_{t}^{3}\right)
\end{array}
\]</span> For uniform distortions, the longitudinal and transverse restoring potentials have "stiffness constants" given by <span class="math display">\[
\frac{K}{\xi_{\ell}^{2}} \equiv t+12 u \bar{m}^{2}=\left.\frac{\partial^{2} \Psi(m)}{\partial \phi_{\ell}^{2}}\right|_{\bar{m}}=\left\{\begin{array}{ll}
t &amp; \text { for } t&gt;0 \\
-2 t &amp; \text { for } t&lt;0
\end{array}\right.
\]</span> and <span class="math display">\[
\frac{K}{\xi_{t}^{2}} \equiv t+4 u \bar{m}^{2}=\left.\frac{\partial^{2} \Psi(m)}{\partial \phi_{t}^{2}}\right|_{\bar{m}}=\left\{\begin{array}{ll}
t &amp; \text { for } t&gt;0 \\
0 &amp; \text { for } t&lt;0
\end{array}\right.
\]</span> (The physical significance of the length scales <span class="math inline">\(\xi_{\ell}\)</span> and <span class="math inline">\(\xi_{t}\)</span> will soon become apparent.) Note that there is no distinction between longitudinal and transverse components for the paramagnet <span class="math inline">\((t&gt;0) .\)</span> For the ordered magnet in <span class="math inline">\(t&lt;0,\)</span> there is no restoring force for the transverse fluctuations which correspond to the Goldstone modes discussed in the previous section.</p>
<p>Following the change of variables to the Fourier modes, <span class="math inline">\(\phi( x )=\)</span> <span class="math inline">\(\sum_{ q } \phi_{ q } e ^{ iq \cdot x } / \sqrt{V},\)</span> the probability of a particular fluctuation configuration is given by <span class="math display">\[
P \left[\left\{\phi_{\ell, q } ; \phi_{t, q }\right\}\right] \propto \prod_{ q } \exp \left\{-\frac{K}{2}\left(q^{2}+\xi_{\ell}^{-2}\right)\left|\phi_{\ell, q }\right|^{2}\right\} \cdot \exp \left\{-\frac{K}{2}\left(q^{2}+\xi_{t}^{-2}\right)\left|\phi_{t, q }\right|^{2}\right\}
\]</span> Clearly each mode behaves as a Gaussian random variable of zero mean, and the two-point correlation functions are <span class="math display">\[
\left\langle\phi_{\alpha, q } \phi_{\beta, q ^{\prime}}\right\rangle=\frac{\delta_{\alpha, \beta} \delta_{ q ,- q ^{\prime}}}{K\left(q^{2}+\xi_{\alpha}^{-2}\right)}
\]</span> where the indices refer to the longitudinal, or any of the transverse components. By using a spin polarized source of neutrons, the relative orientations can be adjusted to probe either the longitudinal or the transverse correlations. The Lorentzian form, <span class="math inline">\(S( q ) \propto 1 /\left(q^{2}+\xi^{-2}\right),\)</span> usually provides an excellent fit to scattering line shapes away from the critical point. Equation (3.9) indicates that in the ordered phase, longitudinal scattering still gives a Lorentzian form (on top of a delta function at <span class="math inline">\(q = 0\)</span> due to the spontaneous magnetization), while transverse scattering always grows as <span class="math inline">\(1 / q^{2} .\)</span> The same power law decay is also predicted to hold at the critical point, <span class="math inline">\(t=0 .\)</span> Actual experimental fits yield a power law of the form <span class="math display">\[
S\left( q , T=T_{c}\right) \propto \frac{1}{q^{2-\eta}}
\]</span> with a small positive value of <span class="math inline">\(\eta\)</span>.</p>
<p><img src="https://jptanjing.oss-cn-beijing.aliyuncs.com/img/image-20210223233405308.png" srcset="/img/loading.gif" /></p>
<blockquote>
<p>Fig. 3.1 The intensity of scattering by magnetic fluctuations for <span class="math inline">\(t&gt;0\)</span> (left), and <span class="math inline">\(t&lt;0\)</span> (right). The dashed line on the right indicates the transverse scattering intensity.</p>
</blockquote>
<h2 id="correlation-functions-and-susceptibilities">Correlation functions and susceptibilities</h2>
<p>We can also examine the extent of fluctuations in real space. The aver<span class="math inline">\(\operatorname{ages}\left\langle\phi_{\alpha}( x )\right\rangle=\left\langle m_{\alpha}( x )-\bar{m}_{\alpha}\right\rangle,\)</span> are clearly zero, and the connected correlation function is <span class="math display">\[
\begin{aligned}
G_{\alpha, \beta}^{c}\left( x , x ^{\prime}\right) &amp; \equiv\left\langle\left(m_{\alpha}( x )-\bar{m}_{\alpha}\right)\left(m_{\beta}\left( x ^{\prime}\right)-\bar{m}_{\beta}\right)\right\rangle \\
&amp;=\left\langle\phi_{\alpha}( x ) \phi_{\beta}\left( x ^{\prime}\right)\right\rangle=\frac{1}{V} \sum_{ q , q ^{\prime}} e ^{ i q \cdot x + i q ^{\prime} \cdot x ^{\prime}}\left\langle\phi_{\alpha, q } \phi_{\beta, q ^{\prime}}\right\rangle
\end{aligned}
\]</span> Using Eq. (3.9), we obtain <span class="math display">\[
G_{\alpha, \beta}^{c}\left( x , x ^{\prime}\right)=\frac{\delta_{\alpha, \beta}}{V} \sum_{ q } \frac{ e ^{ i q \cdot\left( x - x ^{\prime}\right)}}{K\left(q^{2}+\xi_{\alpha}^{-2}\right)} \equiv-\frac{\delta_{\alpha, \beta}}{K} I_{d}\left( x - x ^{\prime}, \xi_{\alpha}\right)
\]</span> where in the continuum limit, <span class="math display">\[
I_{d}( x , \xi)=-\int \frac{ d ^{d} q }{(2 \pi)^{d}} \frac{ e ^{ i q \cdot x }}{q^{2}+\xi^{-2}}
\]</span> Alternatively, <span class="math inline">\(I_{d}\)</span> is the solution to the following differential equation <span class="math display">\[
\nabla^{2} I_{d}(x)=\int \frac{ d ^{d} q }{(2 \pi)^{d}} \frac{q^{2} e ^{ i q \cdot x }}{q^{2}+\xi^{-2}}=\int \frac{ d ^{d} q }{(2 \pi)^{d}}\left[1-\frac{\xi^{-2}}{q^{2}+\xi^{-2}}\right] e ^{ i q \cdot x }=\delta^{d}( x )+\frac{I_{d}( x )}{\xi^{2}}
\]</span> The solution is spherically symmetric, satisfying <span class="math display">\[
\frac{ d ^{2} I_{d}}{ d x^{2}}+\frac{d-1}{x} \frac{ d I_{d}}{ d x}=\frac{I_{d}}{\xi^{2}}+\delta^{d}( x )
\]</span> We can try out a solution that decays exponentially at large distances as <span class="math display">\[
I_{d}(x) \propto \frac{\exp (-x / \xi)}{x^{p}}
\]</span> (We have anticipated the presence of a subleading power law.) The derivatives of <span class="math inline">\(I_{d}\)</span> are given by <span class="math display">\[
\begin{aligned}
\frac{ d I_{d}}{ d x} &amp;=-\left(\frac{p}{x}+\frac{1}{\xi}\right) I_{d} \\
\frac{ d ^{2} I_{d}}{ d x^{2}} &amp;=\left(\frac{p(p+1)}{x^{2}}+\frac{2 p}{x \xi}+\frac{1}{\xi^{2}}\right) I_{d}
\end{aligned}
\]</span> For <span class="math inline">\(x \neq 0,\)</span> the requirement that Eq. (3.16) satisfies Eq. (3.15) gives <span class="math display">\[
\frac{p(p+1)}{x^{2}}+\frac{2 p}{x \xi}+\frac{1}{\xi^{2}}-\frac{p(d-1)}{x^{2}}-\frac{(d-1)}{x \xi}=\frac{1}{\xi^{2}}
\]</span> The choice of <span class="math inline">\(\xi\)</span> as the decay length ensures that the constant terms in the above equation cancel. The exponent <span class="math inline">\(p\)</span> is determined by requiring the next largest terms to cancel. For <span class="math inline">\(x \ll \xi,\)</span> the <span class="math inline">\(1 / x^{2}\)</span> terms are the next most important; we must set <span class="math inline">\(p(p+1)=p(d-1),\)</span> and <span class="math inline">\(p=d-2 .\)</span> This is the familiar exponent for Coulomb interactions, and indeed at this length scale the correlations don't feel the presence of <span class="math inline">\(\xi .\)</span> As demonstrated in the next section, the properly normalized result in this limit is <span class="math display">\[
I_{d}(x) \simeq C_{d}(x)=\frac{x^{2-d}}{(2-d) S_{d}} \quad(x \ll \xi)
\]</span> (Note that a constant term can always be added to the solution to satisfy the limits appropriate to the correlation function under study.) At large distances <span class="math inline">\(x \gg \xi,\)</span> the <span class="math inline">\(1 /(x \xi)\)</span> term dominates Eq. <span class="math inline">\((3.18),\)</span> and its vanishing implies <span class="math inline">\(p=\)</span> <span class="math inline">\((d-1) / 2 .\)</span> Matching to Eq. (3.19) at <span class="math inline">\(x \approx \xi\)</span> yields <span class="math display">\[
I_{d}(x) \simeq \frac{\xi^{(3-d) / 2}}{(2-d) S_{d} x^{(d-1) / 2}} \exp (-x / \xi) \quad(x \gg \xi)
\]</span> <img src="http://jptanjing.oss-cn-beijing.aliyuncs.com/img/image-20210224004445544.png" srcset="/img/loading.gif" alt="image-20210224004445544" /></p>
<p>From Eq. (3.12), we observe that transverse and longitudinal correlations behave differently. Close to the critical point, the longitudinal correlation length (Eq. 3.6) behaves as <span class="math display">\[
\xi_{\ell}=\left\{\begin{array}{ll}
t^{-1 / 2} / \sqrt{K} &amp; \text { for } t&gt;0 \\
(-2 t)^{-1 / 2} / \sqrt{K} &amp; \text { for } t&lt;0
\end{array}\right.
\]</span> The singularities can be described by <span class="math inline">\(\xi_{\pm} \simeq \xi_{0} B_{\pm}|t|^{-\nu_{\pm}},\)</span> where <span class="math inline">\(\nu_{\pm}=1 / 2\)</span> and <span class="math inline">\(B_{+} / B_{-}=\sqrt{2}\)</span> are universal, while <span class="math inline">\(\xi_{0} \propto 1 / \sqrt{K}\)</span> is not. The transverse correlation length (Eq. 3.7) equals <span class="math inline">\(\xi_{\ell}\)</span> for <span class="math inline">\(t&gt;0,\)</span> and is infinite for all <span class="math inline">\(t&lt;0\)</span>.</p>
<p>Equation (3.19) implies that right at <span class="math inline">\(T_{c},\)</span> correlations decay as <span class="math inline">\(1 / x^{d-2}\)</span>. Actually, the decay exponent is usually indicated by <span class="math inline">\(1 / x^{d-2+\eta}\)</span>, where <span class="math inline">\(\eta\)</span> is the same exponent introduced in Eq. (3.10). Integrating the connected correlation functions results in bulk susceptibilities. For example, the divergence of the longitudinal susceptibility is also obtained from, <span class="math display">\[
\chi_{\ell} \propto \int d ^{d} x G_{\ell}^{c}( x ) \propto \int_{0}^{\xi_{\ell}} \frac{ d ^{d} x}{x^{d-2}} \propto \xi_{\ell}^{2} \simeq A_{\pm} t^{-1}
\]</span> The universal exponents and amplitude ratios are again recovered from the above equation. For <span class="math inline">\(T&lt;T_{c},\)</span> there is no upper cut-off length for transverse correlations, and the divergence of the transverse susceptibility can be related to the system size <span class="math inline">\(L,\)</span> as <span class="math display">\[
\chi_{t} \propto \int d ^{d} x G_{t}^{c}( x ) \propto \int_{0}^{L} \frac{ d ^{d} x}{x^{d-2}} \propto L^{2}
\]</span></p>
<h2 id="lower-critical-dimension">Lower critical dimension</h2>
<p>In chapter 2 we discussed how the breaking of a continuous symmetry is accompanied by the appearance of low energy excitations (Goldstone modes). These modes are easily excited by thermal fluctuations, and we may inquire about the effect of such fluctuations on the ordered phase. Let us first consider the case of a superfluid in the ordered phase, with a local order parameter (see Eq. 2.21) <span class="math inline">\(\psi\left( x =|\psi( x )| e ^{ i \theta( x )}\right.\)</span>. Assuming that the amplitude of the order parameter is uniform, the probability of a particular configuration is given by <span class="math display">\[
P [\theta( x )] \propto \exp \left[-\frac{\bar{K}}{2} \int d ^{d} x (\nabla \theta)^{2}\right]
\]</span> Alternatively, in terms of the Fourier components, <span class="math display">\[
P [\theta( q )] \propto \exp \left[-\frac{\bar{K}}{2} \sum_{ q } q^{2}|\theta( q )|^{2}\right] \propto \prod_{ q } p\left(\theta_{ q }\right)
\]</span> Each mode <span class="math inline">\(\theta_{ q }\)</span> is an independent random variable with a Gaussian distribution of zero mean, and with <span class="math display">\[
\left\langle\theta_{ q } \theta_{ q ^{\prime}}\right\rangle=\frac{\delta_{ q ,- q ^{\prime}}}{\bar{K} q^{2}}
\]</span> From Eq. (3.26) we can calculate the correlations in the phase <span class="math inline">\(\theta( x )\)</span> in real space. Clearly <span class="math inline">\(\langle\theta( x )\rangle=0\)</span> by symmetry, while <span class="math display">\[
\left\langle\theta( x ) \theta\left( x ^{\prime}\right)\right\rangle=\frac{1}{V} \sum_{ q , q ^{\prime}} e ^{ i q \cdot x + i q ^{\prime} \cdot x ^{\prime}}\left\langle\theta_{ q } \theta_{ q ^{\prime}}\right\rangle=\frac{1}{V} \sum_{ q } \frac{ e ^{ i q \cdot\left( x - x ^{\prime}\right)}}{\bar{K} q^{2}}
\]</span> In the continuum limit, the sum can be replaced by an integral <span class="math inline">\(\left(\sum_{ q } \mapsto\right.\)</span> <span class="math inline">\(\left.V \int d ^{d} q /(2 \pi)^{d}\right),\)</span> and <span class="math display">\[
\left\langle\theta( x ) \theta\left( x ^{\prime}\right)\right\rangle=\int \frac{ d ^{d} q }{(2 \pi)^{d}} \frac{ e ^{ i q \cdot\left( x - x ^{\prime}\right)}}{\bar{K} q^{2}}=-\frac{C_{d}\left( x - x ^{\prime}\right)}{\bar{K}}
\]</span> The function. <span class="math display">\[
C_{d}( x )=-\int \frac{ d ^{d} q }{(2 \pi)^{d}} \frac{ e ^{ i q \cdot x }}{q^{2}}
\]</span> is the Coulomb potential due to a unit charge at the origin in a <span class="math inline">\(d\)</span> -dimensional space, since it is the solution to <span class="math display">\[
\nabla^{2} C_{d}( x )=\int \frac{ d ^{d} q }{(2 \pi)^{d}} \frac{q^{2}}{q^{2}} e ^{ i q \cdot x }=\delta^{d}( x )
\]</span> We can easily find a solution by using Gauss' theorem, <span class="math display">\[
\int d ^{d} x \nabla^{2} C_{d}=\oint d S \cdot \nabla C_{d}
\]</span> For a spherically symmetric solution, <span class="math inline">\(\nabla C_{d}=\left( d C_{d} / d x\right) \hat{x},\)</span> and the above equation simplifies to <span class="math display">\[
1=S_{d} x^{d-1} \frac{ d C_{d}}{ d x}
\]</span> where <span class="math display">\[
S_{d}=\frac{2 \pi^{d / 2}}{(d / 2-1) !}
\]</span> is the total solid angle (area of unit sphere) in <span class="math inline">\(d\)</span> dimensions. Hence <span class="math display">\[
\frac{ d C_{d}}{ d x}=\frac{1}{S_{d} x^{d-1}} \quad \Longrightarrow \quad C_{d}(x)=\frac{x^{2-d}}{(2-d) S_{d}}+c_{0}
\]</span> where <span class="math inline">\(c_{0}\)</span> is a constant of integration. The long distance behavior of <span class="math inline">\(C_{d}(x)\)</span> changes dramatically at <span class="math inline">\(d=2,\)</span> as <span class="math display">\[
\lim _{x \rightarrow \infty} C_{d}(x)=\left\{\begin{array}{ll}
c_{0} &amp; d&gt;2 \\
\frac{x^{2-d}}{(2-d) S_{d}} &amp; d&lt;2 \\
\frac{\ln (x)}{2 \pi} &amp; d=2
\end{array}\right.
\]</span> The constant of integration can obtained by looking at <span class="math display">\[
\left\langle\left[\theta( x )-\theta\left( x ^{\prime}\right)\right]^{2}\right\rangle=2\left\langle\theta( x )^{2}\right\rangle-2\left\langle\theta( x ) \theta\left( x ^{\prime}\right)\right\rangle
\]</span> which goes to zero as <span class="math inline">\(x \rightarrow x ^{\prime} .\)</span> Hence, <span class="math display">\[
\left\langle\left[\theta( x )-\theta\left( x ^{\prime}\right)\right]^{2}\right\rangle=\frac{2\left(\left| x - x ^{\prime}\right|^{2-d}-a^{2-d}\right)}{\bar{K}(2-d) S_{d}}
\]</span> where <span class="math inline">\(a\)</span> is of the order of the lattice spacing. For <span class="math inline">\(d&gt;2,\)</span> the phase fluctuations are finite, while they become asymptotically large for <span class="math inline">\(d \leq 2\)</span>. Since the phase is bounded by <span class="math inline">\(2 \pi,\)</span> this implies that longrange order in the phase is destroyed. This result becomes more apparent by examining the effect of phase fluctuations on the two-point correlation function <span class="math display">\[
\left\langle\psi( x ) \psi^{*}( 0 )\right\rangle=\bar{\psi}^{2}\left\langle e ^{ i [\theta( x )-\theta(0)]}\right\rangle
\]</span> (Since amplitude fluctuations are ignored, we are in fact looking at a transverse correlation function.) We shall prove later on that for any collection of Gaussian distributed variables, <span class="math display">\[
\langle\exp (\alpha \theta)\rangle=\exp \left(\frac{\alpha^{2}}{2}\left\langle\theta^{2}\right\rangle\right)
\]</span> Taking this result for granted, we obtain <span class="math display">\[
\left\langle\psi( x ) \psi^{*}(0)\right\rangle=\bar{\psi}^{2} \exp \left[-\frac{1}{2}\left\langle[\theta( x )-\theta( 0 )]^{2}\right\rangle\right]=\bar{\psi}^{2} \exp \left[-\frac{x^{2-d}-a^{2-d}}{\bar{K}(2-d) S_{d}}\right]
\]</span> and asymptotically <span class="math display">\[
\lim _{x \rightarrow \infty}\left\langle\psi( x ) \psi^{*}( 0 )\right\rangle=\left\{\begin{array}{ll}
\overline{\psi^{\prime}}^{2} &amp; \text { for } d&gt;2 \\
0 &amp; \text { for } d \leq 2
\end{array}\right.
\]</span> The saddle point approximation to the order parameter <span class="math inline">\(\bar{\psi}\)</span> was obtained by ignoring fluctuations. The above result indicates that inclusion of phase fluctuations leads to a reduction of order in <span class="math inline">\(d&gt;2,\)</span> and its complete destruction in <span class="math inline">\(d \leq 2\)</span> The above example typifies a more general result known as the MerminWagner theorem. The theorem states that there is no spontaneous breaking of a continuous symmetry in systems with short-range interactions in dimensions <span class="math inline">\(d \leq 2\)</span>. Some corollaries to this theorem are:</p>
<ul>
<li><ol type="1">
<li>The borderline dimensionality of two, known as the lower critical dimension, has to be treated carefully. As we shall demonstrate later on in the course, there is in fact a phase transition for the two-dimensional superfluid, although there is no true long-range order.</li>
</ol></li>
<li><ol start="2" type="1">
<li>There are no Goldstone modes when the broken symmetry is discrete (e.g. for <span class="math inline">\(n=1\)</span> ). In such cases, long-range order is possible down to the lower critical dimension of <span class="math inline">\(d_{\ell}=1\)</span></li>
</ol></li>
</ul>
<h2 id="comparison-to-experiments">Comparison to experiments</h2>
<p>The true test of the validity of the theoretical results comes from comparison to experiments. A rather rough table of critical exponents is provided below for a quick check: <span class="math display">\[
\begin{array}{llllll}
\hline \hline \text { Transition type } &amp; \text { Material } &amp; \alpha &amp; \beta &amp; \gamma &amp; \nu \\
\hline \text { Ferromagnets }(n=3) &amp; Fe , Ni &amp; -0.1 &amp; 0.4 &amp; 1.3 &amp; \\
\text { Superfluid }(n=2) &amp; He ^{4} &amp; 0 &amp; 0.3 &amp; 1.3 &amp; 0.7 \\
\text { Liquid-gas }(n=1) &amp; CO _{2}, Xe &amp; 0.1 &amp; 0.3 &amp; 1.2 &amp; 0.7 \\
\text { Ferroelectrics } &amp; \text { TGS } &amp; 0 &amp; 1 / 2 &amp; 1 &amp; 1 / 2 \\
\text { and superconductors } &amp; &amp; &amp; &amp; &amp; \\
\hline \text { Mean-field theory } &amp; &amp; 0 &amp; 1 / 2 &amp; 1 &amp; 1 / 2 \\
\hline \hline
\end{array}
\]</span> The exponents are actually known to much better accuracy than indicated in this table. The final row (mean-field theory) refers to the results obtained from the saddle point approximation. They agree only with the experiments on ferroelectric and superconducting materials. The disagreement between the exponents for different values of <span class="math inline">\(n\)</span> suggests that the mean-field results are too universal, and leave out some essential dependence on <span class="math inline">\(n\)</span> (and <span class="math inline">\(d\)</span> ). How do we account for these discrepancies? The starting point of the Landau-Ginzburg Hamiltonian is sufficiently general to be trustworthy. The difficulty is in the saddle point method used in the evaluation of its partition function, as will become apparent in the following sections.</p>
<h2 id="gaussian-integrals">Gaussian integrals</h2>
<p>In the previous section the energy cost of fluctuations was calculated at quadratic order. These fluctuations also modify the saddle point free energy. Before calculating this modification, we take a short (but necessary) mathematical diversion on computing Gaussian integrals. The simplest Gaussian integral involves one variable <span class="math inline">\(\phi\)</span>, <span class="math display">\[
J _{1}=\int_{-\infty}^{\infty} d \phi e ^{-\frac{K}{2} \phi^{2}+h \phi}=\sqrt{\frac{2 \pi}{K}} e ^{\frac{h^{2}}{2 K}}
\]</span> By taking derivatives of the above expression with respect to <span class="math inline">\(h,\)</span> integrals involving powers of <span class="math inline">\(\phi\)</span> are generated; e.g. <span class="math display">\[
\begin{aligned}
\frac{ d }{ d h}: \int_{-\infty}^{\infty} d \phi \phi e ^{-\frac{K}{2} \phi^{2}+h \phi} &amp;=\sqrt{\frac{2 \pi}{K}} e ^{\frac{h^{2}}{2 K}} \cdot \frac{h}{K} \\
\frac{ d ^{2}}{ d h^{2}}: \int_{-\infty}^{\infty} d \phi \phi^{2} e ^{-\frac{K}{2} \phi^{2}+h \phi} &amp;=\sqrt{\frac{2 \pi}{K}} e ^{\frac{h^{2}}{2 K}} \cdot\left[\frac{1}{K}+\frac{h^{2}}{K^{2}}\right]
\end{aligned}
\]</span> If the integrand represents the probability density of the random variable <span class="math inline">\(\phi,\)</span> the above integrals imply the moments <span class="math inline">\(\langle\phi\rangle=h / K,\)</span> and <span class="math inline">\(\left\langle\phi^{2}\right\rangle=h^{2} / K^{2}+1 / K .\)</span> The corresponding cumulants are <span class="math inline">\(\langle\phi\rangle_{c}=\langle\phi\rangle=h / K,\)</span> and <span class="math inline">\(\left\langle\phi^{2}\right\rangle_{c}=\left\langle\phi^{2}\right\rangle-\langle\phi\rangle^{2}=\)</span> <span class="math inline">\(1 / K .\)</span> In fact all higher order cumulants of the Gaussian distribution are zero since <span class="math display">\[
\left\langle e ^{- i k \phi}\right\rangle \equiv \exp \left[\sum_{\ell=1}^{\infty} \frac{(- i k)^{\ell}}{\ell !}\left\langle\phi^{\ell}\right\rangle_{c}\right]=\exp \left[- i k h-\frac{k^{2}}{2 K}\right]
\]</span> Now consider the following Gaussian integral involving <span class="math inline">\(N\)</span> variables, <span class="math display">\[
J _{N}=\int_{-\infty}^{\infty} \prod_{i=1}^{N} d \phi_{i} \exp \left[-\sum_{i, j} \frac{K_{i, j}}{2} \phi_{i} \phi_{j}+\sum_{i} h_{i} \phi_{i}\right]
\]</span> It can be reduced to a product of <span class="math inline">\(N\)</span> one-dimensional integrals by diagonalizing the matrix <span class="math inline">\(K \equiv K_{i, j} .\)</span> Since we need only consider symmetric matrices <span class="math inline">\(\left(K_{i, j}=\right.\)</span> <span class="math inline">\(\left.K_{j, i}\right),\)</span> the eigenvalues are real, and the eigenvectors can be made orthonormal. Let us denote the eigenvectors and eigenvalues of <span class="math inline">\(K\)</span> by <span class="math inline">\(\hat{q}\)</span> and <span class="math inline">\(K_{q},\)</span> respectively,</p>
<p>i.e. <span class="math inline">\(K \hat{q}=K_{q} \hat{q} .\)</span> The vectors <span class="math inline">\(\{\hat{q}\}\)</span> form a new coordinate basis in the original <span class="math inline">\(N\)</span> -dimensional space. Any point in this space can be represented either by coordinates <span class="math inline">\(\left\{\phi_{i}\right\},\)</span> or <span class="math inline">\(\left\{\tilde{\phi}_{q}\right\}\)</span> with <span class="math inline">\(\phi_{i}=\sum_{q} \tilde{\phi}_{q} \hat{q}_{i} .\)</span> We can now change the integration variables from <span class="math inline">\(\left\{\phi_{i}\right\}\)</span> to <span class="math inline">\(\left\{\tilde{\phi}_{q}\right\} .\)</span> The Jacobian associated with this unitary transformation is unity, and <span class="math display">\[
J _{N}=\prod_{q=1}^{N} \int_{-\infty}^{\infty} d \tilde{\phi}_{q} \exp \left[-\frac{K_{q}}{2} \tilde{\phi}_{q}^{2}+\tilde{h}_{q} \tilde{\phi}_{q}\right]=\prod_{q=1}^{N} \sqrt{\frac{2 \pi}{K_{q}}} \exp \left[\frac{\tilde{h}_{q} K_{q}^{-1} \tilde{h}_{q}}{2}\right]
\]</span> The final expression can be represented in terms of the original coordinates by using the inverse matrix <span class="math inline">\(K ^{-1},\)</span> such that <span class="math inline">\(K ^{-1} K = 1 .\)</span> Since the determinant of the matrix is independent of the choice of basis, det <span class="math inline">\(K =\prod_{q} K_{q},\)</span> and <span class="math display">\[
J _{N}=\sqrt{\frac{(2 \pi)^{N}}{\operatorname{det} K }} \exp \left[\sum_{i, j} \frac{K_{i, j}^{-1}}{2} h_{i} h_{j}\right]
\]</span> Regarding <span class="math inline">\(\left\{\phi_{i}\right\}\)</span> as Gaussian random variable distributed with a joint probability distribution function proportional to the integrand of Eq. (3.43), the joint characteristic function is given by <span class="math display">\[
\left\langle e ^{- i \Sigma_{j} k_{j} \phi_{j}}\right\rangle=\exp \left[- i \sum_{i, j} K_{i, j}^{-1} h_{i} k_{j}-\sum_{i, j} \frac{K_{i, j}^{-1}}{2} k_{i} k_{j}\right]
\]</span> Moments of the distribution are obtained from derivatives of the characteristic function with respect to <span class="math inline">\(k_{i}\)</span>, and cumulants from derivatives of its logarithm. Hence, Eq. (3.46) implies <span class="math display">\[
\left\{\begin{array}{l}
\left\langle\phi_{i}\right\rangle_{c}=\sum_{j} K_{i, j}^{-1} h_{j} \\
\left\langle\phi_{i} \phi_{j}\right\rangle_{c}=K_{i, j}^{-1}
\end{array}\right.
\]</span> Another useful form of Eq. (3.46) is <span class="math display">\[
\langle\exp (A)\rangle=\exp \left[\langle A\rangle_{c}+\frac{1}{2}\left\langle A^{2}\right\rangle_{c}\right]
\]</span> where <span class="math inline">\(A=\sum_{i} a_{i} \phi_{i}\)</span> is any linear combination of Gaussian distributed variables. We used this result earlier in computing the order parameter correlations in the presence of phase fluctuations in a superfluid.</p>
<p>Gaussian functional integrals are a limiting case of the above many variable integrals. Consider the points <span class="math inline">\(i\)</span> as the sites of a <span class="math inline">\(d\)</span> -dimensional lattice and let the spacing go to zero. In the continuum limit, <span class="math inline">\(\left\{\phi_{i}\right\}\)</span> go over to a function <span class="math inline">\(\phi( x )\)</span> and the matrix <span class="math inline">\(K_{i j}\)</span> is replaced by a kernel <span class="math inline">\(K\left( x , x ^{\prime}\right) .\)</span> The natural generalization of Eq. (3.45) is <span class="math display">\[
\begin{array}{l}
\int_{-\infty}^{\infty} D \phi( x ) \exp \left[-\int d ^{d} x d ^{d} x ^{\prime} \frac{K\left( x , x ^{\prime}\right)}{2} \phi( x ) \phi\left( x ^{\prime}\right)+\int d ^{d} x h( x ) \phi( x )\right] \\
\propto(\operatorname{det} K )^{-1 / 2} \exp \left[\int d ^{d} x d ^{d} x ^{\prime} \frac{K^{-1}\left( x , x ^{\prime}\right)}{2} h( x ) h\left( x ^{\prime}\right)\right]
\end{array}
\]</span> where the inverse kernel <span class="math inline">\(K^{-1}\left( x , x ^{\prime}\right)\)</span> satisfies <span class="math display">\[
\int d ^{d} x ^{\prime} K\left( x , x ^{\prime}\right) K^{-1}\left( x ^{\prime}, x ^{\prime \prime}\right)=\delta^{d}\left( x - x ^{\prime \prime}\right)
\]</span> The notation <span class="math inline">\(D \phi( x )\)</span> is used to denote the functional integral. There is a constant of proportionality, <span class="math inline">\((2 \pi)^{N / 2},\)</span> left out of Eq. <span class="math inline">\((3.49) .\)</span> Although formally infinite in the continuum limit of <span class="math inline">\(N \rightarrow \infty,\)</span> it does not affect the averages that are obtained as derivatives of such integrals. In particular, for Gaussian distributed functions, Eq. (3.47) generalizes to <span class="math display">\[
\left\{\begin{array}{l}
\langle\phi( x )\rangle_{c} \quad=\int d ^{d} x ^{\prime} K^{-1}\left( x , x ^{\prime}\right) h\left( x ^{\prime}\right) \\
\left\langle\phi( x ) \phi\left( x ^{\prime}\right)\right\rangle_{c}=K^{-1}\left( x , x ^{\prime}\right)
\end{array}\right.
\]</span> In dealing with small fluctuations to the Landau-Ginzburg Hamiltonian, we encountered the quadratic form <span class="math display">\[
\int d ^{d} x \left[(\nabla \phi)^{2}+\phi^{2} / \xi^{2}\right] \equiv \int d ^{d} x d ^{d} x ^{\prime} \phi\left( x ^{\prime}\right) \delta^{d}\left( x - x ^{\prime}\right)\left(-\nabla^{2}+\xi^{-2}\right) \phi( x )
\]</span> which implies the kernel <span class="math display">\[
K\left( x , x ^{\prime}\right)=K \delta^{d}\left( x - x ^{\prime}\right)\left(-\nabla^{2}+\xi^{-2}\right)
\]</span> Following Eq. <span class="math inline">\((3.50),\)</span> the inverse kernel satisfies <span class="math display">\[
K \int d ^{d} x ^{\prime \prime} \delta^{d}\left( x - x ^{\prime \prime}\right)\left(-\nabla^{2}+\xi^{-2}\right) K^{-1}\left( x ^{\prime \prime}- x ^{\prime}\right)=\delta^{d}\left( x ^{\prime}- x \right)
\]</span> which implies the differential equation <span class="math display">\[
K\left(-\nabla^{2}+\xi^{-2}\right) K^{-1}( x )=\delta^{d}( x )
\]</span> Comparing with Eq. (3.14) indicates <span class="math inline">\(K^{-1}( x )=\langle\phi( x ) \phi( 0 )\rangle=-I_{d}( x ) / K,\)</span> as obtained before by a less direct method.</p>
<h2 id="fluctuation-corrections-to-the-saddle-point">Fluctuation corrections to the saddle point</h2>
<p>We can now examine how fluctuations around the saddle point solution modify the free energy, and other macroscopic properties. Starting with Eq. (3.5), the partition function including small fluctuations is <span class="math display">\[
\begin{aligned}
Z \approx \exp \left[-V\left(\frac{t}{2} \bar{m}^{2}+u \bar{m}^{4}\right)\right] &amp; \int D \phi_{\ell}( x ) \exp \left\{-\frac{K}{2} \int d ^{d} x \left[\left(\nabla \phi_{\ell}\right)^{2}+\frac{\phi_{\ell}^{2}}{\xi_{\ell}^{2}}\right]\right\} \\
&amp; \cdot \int D \phi_{t}( x ) \exp \left\{-\frac{K}{2} \int d ^{d} x \left[\left(\nabla \phi_{t}\right)^{2}+\frac{\phi_{t}^{2}}{\xi_{t}^{2}}\right]\right\}
\end{aligned}
\]</span> Each of the Gaussian kernels is diagonalized by the Fourier transforms <span class="math display">\[
\tilde{\phi}( q )=\int d ^{d} x \exp (- i q \cdot x ) \phi( x ) / \sqrt{V}
\]</span> and with corresponding eigenvalues <span class="math inline">\(K( q )=K\left(q^{2}+\xi^{-2}\right) .\)</span> The resulting determinant of <span class="math inline">\(K\)</span> is a product of such eigenvalues, and hence <span class="math display">\[
\ln \operatorname{det} K =\sum_{ q } \ln K( q )=V \int \frac{ d ^{d} q }{(2 \pi)^{d}} \ln \left[K\left(q^{2}+\xi^{-2}\right)\right]
\]</span> The free energy resulting from Eq. (3.56) is then given by <span class="math display">\[
\begin{aligned}
\beta f=&amp;-\frac{\ln Z}{V}=\frac{t \bar{m}^{2}}{2}+u \bar{m}^{4}+\frac{1}{2} \int \frac{ d ^{d} q }{(2 \pi)^{d}} \ln \left[K\left(q^{2}+\xi_{\ell}^{-2}\right)\right] \\
&amp;+\frac{n-1}{2} \int \frac{ d ^{d} q }{(2 \pi)^{d}} \ln \left[K\left(q^{2}+\xi_{t}^{-2}\right)\right]
\end{aligned}
\]</span> (Note that there are <span class="math inline">\(n-1\)</span> transverse components.) Using the dependence of the correlation lengths on reduced temperature, the singular part of the heat capacity is obtained as <span class="math display">\[
C_{\text {singular }} \propto-\frac{\partial^{2}(\beta f)}{\partial^{2} t}=\left\{\begin{array}{ll}
0+\frac{n}{2} \int \frac{ d ^{d} q }{(2 \pi)^{d}} \frac{1}{\left(K q^{2}+t\right)^{2}} &amp; \text { for } t&gt;0 \\
\frac{1}{8 u}+2 \int \frac{ d ^{d} q }{(2 \pi)^{d}} \frac{1}{\left(K q^{2}-2 t\right)^{2}} &amp; \text { for } t&lt;0 .
\end{array}\right.
\]</span> The correction terms are proportional to <span class="math display">\[
C_{F}=\frac{1}{K^{2}} \int \frac{ d ^{d} q }{(2 \pi)^{d}} \frac{1}{\left(q^{2}+\xi^{-2}\right)^{2}}
\]</span> The integral has dimensions of (length) <span class="math inline">\(^{4-d},\)</span> and changes behavior at <span class="math inline">\(d=4 .\)</span> For <span class="math inline">\(d&gt;4\)</span> the integral diverges at large <span class="math inline">\(q ,\)</span> and is dominated by the upper cutoff <span class="math inline">\(\Lambda \simeq 1 / a,\)</span> where <span class="math inline">\(a\)</span> is the lattice spacing. For <span class="math inline">\(d&lt;4,\)</span> the integral is convergent in both limits. It can be made dimensionless by rescaling <span class="math inline">\(q\)</span> by <span class="math inline">\(\xi^{-1},\)</span> and is hence proportional to <span class="math inline">\(\xi^{4-d} .\)</span> Therefore <span class="math display">\[
C_{F} \simeq \frac{1}{K^{2}}\left\{\begin{array}{ll}
a^{4-d} &amp; \text { for } d&gt;4 \\
\xi^{4-d} &amp; \text { for } d&lt;4
\end{array}\right.
\]</span> In dimensions <span class="math inline">\(d&gt;4,\)</span> fluctuation corrections to the heat capacity add a constant term to the background on each side of the transition. However, the primary form of the singularity, a discontinuity in <span class="math inline">\(C,\)</span> is not changed. For <span class="math inline">\(d&lt;4\)</span> the divergence of <span class="math inline">\(\xi \propto t^{-1 / 2},\)</span> at the transition leads to a correction term from Eq. (3.61) which is more important than the original discontinuity. Indeed, the correction term corresponds to an exponent <span class="math inline">\(\alpha=(4-d) / 2 .\)</span> However, this is only the first correction to the saddle point result. The divergence of <span class="math inline">\(C_{F}\)</span> merely implies that the saddle point conclusions are no longer reliable in dimensions <span class="math inline">\(d \leq 4,\)</span> below the so-called upper critical dimension. Although we obtained this dimension by looking at the fluctuation corrections to the heat capacity, we would have reached the same conclusion in examining the singular part of any other quantity, such as magnetization or susceptibility. The contributions due to fluctuations always modify the leading singular behavior, and hence the critical exponents, in dimensions <span class="math inline">\(d \leq 4\)</span></p>
<h2 id="the-ginzburg-criterion">The Ginzburg criterion</h2>
<p>We have thus established the importance of fluctuations, and identified them as the probable reason for the failure of the saddle point approximation to correctly describe the observed exponents. However, as noted earlier, there are some materials, such as superconductors, in which the experimental results are well fitted to the singular forms predicted by this approximation. Can we quantify why fluctuations are less important in superconductors than in other phase transitions?</p>
<p>Equation (3.61) indicates that fluctuation corrections become important due to the divergence of the correlation length. Within the saddle point approximation, the correlation length diverges as <span class="math inline">\(\xi \approx \xi_{0}|t|^{-1 / 2},\)</span> where <span class="math inline">\(t=\left(T_{c}-T\right) / T_{c}\)</span> is the reduced temperature, and <span class="math inline">\(\xi_{0} \approx \sqrt{K}\)</span> is a microscopic length scale. In principle, <span class="math inline">\(\xi_{0}\)</span> can be measured experimentally from fitting scattering line shapes. It has to approximately equal the size of the units that undergo ordering at the phase transition. For the liquid-gas transition, <span class="math inline">\(\xi_{0}\)</span> can be estimated as <span class="math inline">\(\left(v_{c}\right)^{1 / 3}\)</span>, where <span class="math inline">\(v_{c}\)</span> is the critical atomic volume. In superfluids, <span class="math inline">\(\xi_{0}\)</span> is approximately the thermal wavelength <span class="math inline">\(\lambda(T)\)</span>. Both these estimates are of the order of a few atomic spacings, <span class="math inline">\(1-10\)</span> A. On the other hand, the underlying unit for superconductors is a Cooper pair. The paired electrons are forced apart by their Coulomb repulsion, resulting in a relatively large separation of <span class="math inline">\(\xi_{0} \approx 10^{3} \AA\)</span>.</p>
<p>The importance of fluctuations can be gauged by comparing the two terms in Eq. (3.59)<span class="math inline">\(;\)</span> the saddle point discontinuity <span class="math inline">\(\Delta C_{ SP } \propto 1 / u,\)</span> and the correction term <span class="math inline">\(C_{F}\)</span>. Since <span class="math inline">\(K \propto \xi_{0}^{2},\)</span> the correction term is proportional to <span class="math inline">\(\xi_{0}^{-d} t^{-(4-d) / 2} .\)</span> Thus fluctuations are important provided, <span class="math display">\[
\xi_{0}^{-d} t^{-\frac{4-d}{2}} \gg \Delta C_{S P} \quad \Longrightarrow \quad|t| \ll t_{G} \simeq \frac{1}{\left(\xi_{0}^{d} \Delta C_{S P}\right)^{\frac{2}{4-d}}}
\]</span> The above requirement is known as the Ginzburg criterion. Naturally in <span class="math inline">\(d&lt;4\)</span> the inequality is satisfied sufficiently close to the critical point. However, the resolution of the experiment may not be good enough to get closer than the Ginzburg reduced temperature <span class="math inline">\(t_{G} .\)</span> If so, the apparent singularities at reduced temperatures <span class="math inline">\(t&gt;t_{G}\)</span> may show saddle point behavior. It is this apparent discontinuity that then appears in Eq. (3.62), and may be used to self-consistently estimate <span class="math inline">\(t_{G} .\)</span> Clearly, <span class="math inline">\(\Delta C_{S P}\)</span> and <span class="math inline">\(\xi_{0}\)</span> can both be measured in dimensionless units; <span class="math inline">\(\xi_{0}\)</span> in units of atomic size <span class="math inline">\(a,\)</span> and <span class="math inline">\(\Delta C_{S P}\)</span> in units of <span class="math inline">\(N k_{ B } .\)</span> The latter is of the order of unity for most transitions, and thus <span class="math inline">\(t_{G} \approx \xi_{0}^{-6}\)</span> in <span class="math inline">\(d=3 .\)</span> In cases where <span class="math inline">\(\xi_{0}\)</span> is a few atomic spacings, a resolution of <span class="math inline">\(t_{G} \approx 10^{-1}-10^{-2}\)</span> will suffice. However, in superconductors with <span class="math inline">\(\xi_{0} \approx 10^{3} a,\)</span> a resolution of <span class="math inline">\(t_{G}&lt;10^{-18}\)</span> is necessary to see any fluctuation effects. This is much beyond the ability of current apparatus. The newer ceramic high-temperature superconductors have a much smaller coherence length of <span class="math inline">\(\xi_{0} \approx 10 a,\)</span> and they indeed show some effects of fluctuations.</p>
<p>Again, it is worth emphasizing that a similar criterion could have been obtained by examining any other quantity. Fluctuations corrections become important in measurement of a quantity <span class="math inline">\(X\)</span> for <span class="math inline">\(t \ll t_{G}(X) \simeq A(X) \xi_{0}^{-2 d /(4-d)}\)</span>. However, the coefficient <span class="math inline">\(A(X)\)</span> may be different (by one or two orders of magnitude) for different quantities. So, it is in principle possible to observe saddle point behavior in one quantity, while fluctuations are important in another quantity measured at the same resolution. Of course, fluctuations will always become important at sufficiently high resolutions.</p>
<p>A summary of the results obtained so far from the Landau-Ginzburg approach is as follows: - For dimensions <span class="math inline">\(d\)</span> greater than an upper critical dimension of <span class="math inline">\(d_{u}=4,\)</span> the saddle point approximation is valid, and singular behavior at the critical point is described by exponents <span class="math inline">\(\alpha=0, \beta=1 / 2, \gamma=1, \nu=1 / 2,\)</span> and <span class="math inline">\(\eta=0\)</span> - For <span class="math inline">\(d\)</span> less than a lower critical dimension <span class="math inline">\(\left(d_{\ell}=2\right.\)</span> for continuous symmetry, and <span class="math inline">\(d_{\ell}=1\)</span> for discrete symmetry) fluctuations are strong enough to destroy the ordered phase. - In the intermediate dimensions, <span class="math inline">\(d_{\ell} \leq d \leq d_{u},\)</span> fluctuations are strong enough to change the saddle point results, but not sufficiently dominant to completely destroy order. Unfortunately, or happily, this is the case of interest to us in <span class="math inline">\(d=3\)</span>.</p>

            </article>
            <hr>
            <div>
              <div class="post-metas mb-3">
                
                  <div class="post-meta mr-3">
                    <i class="iconfont icon-category"></i>
                    
                      <a class="hover-with-bg" href="/categories/Fields-of-Quantum-ManyBody/">Fields of Quantum ManyBody</a>
                    
                      <a class="hover-with-bg" href="/categories/Fields-of-Quantum-ManyBody/Statistical-Physics-of-Fields/">Statistical Physics of Fields</a>
                    
                  </div>
                
                
                  <div class="post-meta">
                    <i class="iconfont icon-tags"></i>
                    
                      <a class="hover-with-bg" href="/tags/Ginzburg-Landau/">Ginzburg-Landau</a>
                    
                  </div>
                
              </div>
              
                <p class="note note-warning">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-sa/4.0/deed.zh" target="_blank" rel="nofollow noopener noopener">CC BY-SA 4.0 协议</a> ，转载请注明出处！</p>
              
              
                <div class="post-prevnext row">
                  <div class="post-prev col-6">
                    
                    
                      <a href="/2021/03/02/Math_08_Matrix_02/">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">Lanczos方法</span>
                        <span class="visible-mobile">Previous</span>
                      </a>
                    
                  </div>
                  <div class="post-next col-6">
                    
                    
                      <a href="/2021/02/23/Math_07_Stochastic/">
                        <span class="hidden-mobile">随机过程基础</span>
                        <span class="visible-mobile">Next</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </div>
                </div>
              
            </div>

            
          </div>
        </div>
      </div>
    </div>
    
      <div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn">
        <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;TOC</p>
  <div id="tocbot"></div>
</div>


      </div>
    
  </div>
</div>

<!-- Custom -->


    
  </main>

  
    <a id="scroll-top-button" href="#" role="button">
      <i class="iconfont icon-arrowup" aria-hidden="true"></i>
    </a>
  

  
    <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">Search</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v"
                 for="local-search-input">keyword</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>
  

  

  

  <footer class="mt-5">
  <div class="text-center py-3">
    <div>
      <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a>
      <i class="iconfont icon-love"></i>
      <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener">
        <span>Fluid</span></a>
    </div>
    

    

    
  </div>
</footer>

<!-- SCRIPTS -->
<script  src="https://cdn.staticfile.org/jquery/3.4.1/jquery.min.js" ></script>
<script  src="https://cdn.staticfile.org/twitter-bootstrap/4.4.1/js/bootstrap.min.js" ></script>
<script  src="/js/debouncer.js" ></script>
<script  src="/js/main.js" ></script>

<!-- Plugins -->


  
    <script  src="/js/lazyload.js" ></script>
  



  <script defer src="https://cdn.staticfile.org/clipboard.js/2.0.6/clipboard.min.js" ></script>
  <script  src="/js/clipboard-use.js" ></script>







  <script  src="https://cdn.staticfile.org/tocbot/4.11.1/tocbot.min.js" ></script>
  <script>
    $(document).ready(function () {
      var boardCtn = $('#board-ctn');
      var boardTop = boardCtn.offset().top;

      tocbot.init({
        tocSelector: '#tocbot',
        contentSelector: 'article.markdown-body',
        headingSelector: 'h1,h2,h3,h4,h5,h6',
        linkClass: 'tocbot-link',
        activeLinkClass: 'tocbot-active-link',
        listClass: 'tocbot-list',
        isCollapsedClass: 'tocbot-is-collapsed',
        collapsibleClass: 'tocbot-is-collapsible',
        collapseDepth: 1,
        scrollSmooth: true,
        headingsOffset: -boardTop
      });
      if ($('.toc-list-item').length > 0) {
        $('#toc').css('visibility', 'visible');
      }
    });
  </script>



  <script  src="https://cdn.staticfile.org/typed.js/2.0.11/typed.min.js" ></script>
  <script>
    var typed = new Typed('#subtitle', {
      strings: [
        '  ',
        "统计场&nbsp;",
      ],
      cursorChar: "_",
      typeSpeed: 70,
      loop: false,
    });
    typed.stop();
    $(document).ready(function () {
      $(".typed-cursor").addClass("h2");
      typed.start();
    });
  </script>



  <script  src="https://cdn.staticfile.org/anchor-js/4.2.2/anchor.min.js" ></script>
  <script>
    anchors.options = {
      placement: "right",
      visible: "hover",
      
    };
    var el = "h1,h2,h3,h4,h5,h6".split(",");
    var res = [];
    for (item of el) {
      res.push(".markdown-body > " + item)
    }
    anchors.add(res.join(", "))
  </script>



  <script  src="/js/local-search.js" ></script>
  <script>
    var path = "/local-search.xml";
    var inputArea = document.querySelector("#local-search-input");
    inputArea.onclick = function () {
      searchFunc(path, 'local-search-input', 'local-search-result');
      this.onclick = null
    }
  </script>



  <script  src="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.js" ></script>
  <link  rel="stylesheet" href="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.css" />

  <script>
    $('#post img:not(.no-zoom img, img[no-zoom]), img[zoom]').each(
      function () {
        var element = document.createElement('a');
        $(element).attr('data-fancybox', 'images');
        $(element).attr('href', $(this).attr('src'));
        $(this).wrap(element);
      }
    );
  </script>





  

  
    <!-- MathJax -->
    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']]
        },
        options: {
          renderActions: {
            findScript: [10, doc => {
              document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
                const display = !!node.type.match(/; *mode=display/);
                const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
                const text = document.createTextNode('');
                node.parentNode.replaceChild(text, node);
                math.start = { node: text, delim: '', n: 0 };
                math.end = { node: text, delim: '', n: 0 };
                doc.math.push(math);
              });
            }, '', false],
            insertedScript: [200, () => {
              document.querySelectorAll('mjx-container').forEach(node => {
                let target = node.parentNode;
                if (target.nodeName.toLowerCase() === 'li') {
                  target.parentNode.classList.add('has-jax');
                }
              });
            }, '', false]
          }
        }
      };
    </script>

    <script async src="https://cdn.staticfile.org/mathjax/3.0.5/es5/tex-svg.js" ></script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config("");
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->

  
















</body>
</html>

<!DOCTYPE html>
<html lang="en">





<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/favicon.png">
  <link rel="icon" type="image/png" href="/img/favicon.png">
  <meta name="viewport"
        content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="description" content="">
  <meta name="author" content="JPZhuang">
  <meta name="keywords" content="">
  <title>人工智能的新数学 - JPZ</title>

  <link  rel="stylesheet" href="https://cdn.staticfile.org/twitter-bootstrap/4.4.1/css/bootstrap.min.css" />


  <link  rel="stylesheet" href="https://cdn.staticfile.org/github-markdown-css/4.0.0/github-markdown.min.css" />
  <link  rel="stylesheet" href="/lib/hint/hint.min.css" />

  
    
    <link  rel="stylesheet" href="https://cdn.staticfile.org/highlight.js/10.0.0/styles/github-gist.min.css" />
  

  


<!-- 主题依赖的图标库，不要自行修改 -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_yg9cfy8wd6.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_pjno9b9zyxs.css">


<link  rel="stylesheet" href="/css/main.css" />

<!-- 自定义样式保持在最底部 -->


  <script  src="/js/utils.js" ></script>
<meta name="generator" content="Hexo 4.2.1"><!-- hexo-inject:begin --><!-- hexo-inject:end --></head>


<body>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><header style="height: 70vh;">
    <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand"
       href="/">&nbsp;<strong>Physics</strong>&nbsp;</a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                Home
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                Archives
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                Categories
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                Tags
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                About
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" data-toggle="modal" data-target="#modalSearch">&nbsp;&nbsp;<i
                class="iconfont icon-search"></i>&nbsp;&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

    <div class="banner intro-2" id="background" parallax=true
         style="background: url('/img/tag-bg.jpg') no-repeat center center;
           background-size: cover;">
      <div class="full-bg-img">
        <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
          <div class="container text-center white-text fade-in-up">
            <span class="h2" id="subtitle">
              
            </span>

            
              
  <div class="mt-3 post-meta">
    <i class="iconfont icon-date-fill" aria-hidden="true"></i>
    <time datetime="2021-02-03 13:23">
      February 3, 2021 pm
    </time>
  </div>


<div class="mt-1">
  
    
    <span class="post-meta mr-2">
      <i class="iconfont icon-chart"></i>
      1.5k 字
    </span>
  

  
    
    <span class="post-meta mr-2">
      <i class="iconfont icon-clock-fill"></i>
      
      
      25
       分钟
    </span>
  

  
  
</div>

            
          </div>

          
        </div>
      </div>
    </div>
  </header>

  <main>
    
      

<div class="container-fluid">
  <div class="row">
    <div class="d-none d-lg-block col-lg-2"></div>
    <div class="col-lg-8 nopadding-md">
      <div class="container nopadding-md" id="board-ctn">
        <div class="py-5" id="board">
          <div class="post-content mx-auto" id="post">
            
            <article class="markdown-body">
              <p>[TOC]</p>
<h2 id="参考文献">参考文献</h2>
<ol type="1">
<li><a href="https://www.cis.upenn.edu/~jean/math-deep.pdf" target="_blank" rel="noopener">Algebra, Topology, Differential Calculus, and Optimization Theory For Computer Science and Machine Learning</a> Jean Gallier</li>
<li>Mathematics for Machine Learning
<ul>
<li><a href="https://mml-book.github.io/" target="_blank" rel="noopener">Jupyter notebook tutorials</a></li>
<li><a href="https://mml-book.github.io/book/mml-book.pdf" target="_blank" rel="noopener">PDF</a></li>
</ul></li>
<li><a href="https://www.bilibili.com/video/BV1dK4y1Z7uQ/?spm_id_from=333.788.videocard.2" target="_blank" rel="noopener">人工智能的十种新数学</a> <a href="https://www.math.pku.edu.cn/teachers/linw/" target="_blank" rel="noopener">林伟PKU</a></li>
</ol>
<p><img src="https://jptanjing.oss-cn-beijing.aliyuncs.com/img/image-20210203113414639.png" srcset="/img/loading.gif" /></p>
<h3 id="泛函分析">1. 泛函分析</h3>
<p>深度神经网络是有限的神经元，真实的世界非常复杂，真实世界的数据应该来自函数类。比如这篇文章:</p>
<ul>
<li>定义宽度是无限大的极限，这构成了数学上的Banach spaces</li>
<li>再在Banach spaces空间上发展一些理论</li>
</ul>
<p><a href="https://arxiv.org/pdf/2007.15623.pdf" target="_blank" rel="noopener">On the Banach spaces associated with multi-layer ReLU networks Function representation, approximation theory and gradient descent dynamics</a></p>
<p>ABSTRACT. We develop Banach spaces for ReLU neural networks of finite depth <span class="math inline">\(L\)</span> and infinite width. The spaces contain all finite fully connected <span class="math inline">\(L\)</span> -layer networks and their <span class="math inline">\(L^{2}\)</span> -limiting objects under bounds on the natural path-norm. Under this norm, the unit ball in the space for <span class="math inline">\(L\)</span> -layer networks has low Rademacher complexity and thus favorable generalization properties. Functions in these spaces can be approximated by multi-layer neural networks with dimensionindependent convergence rates.</p>
<p>The key to this work is a new way of representing functions in some form of expectations, motivated by multi-layer neural networks. This representation allows us to define a new class of continuous models for machine learning. We show that the gradient flow defined this way is the natural continuous analog of the gradient descent dynamics for the associated multi-layer neural networks. We show that the path-norm increases at most polynomially under this continuous gradient flow dynamics.</p>
<h3 id="群表示论与范畴论">2. 群表示论与范畴论</h3>
<p>群表示论：现在的神经网络的参数非常多，实际上是有冗余性的。在一些变换下，有些神经网络是等价的。用群表示论来研究神经网络的对称性。</p>
<p>范畴论： 用函子描述反向传播。范畴论很抽象，但是为什么可以用来描述神经网络？因为范畴论很适合用来研究函数的复合。</p>
<ol type="1">
<li><a href="https://arxiv.org/abs/2008.01805" target="_blank" rel="noopener">Analytic Characterization of the Hessian in Shallow ReLU Models: A Tale of Symmetry</a></li>
</ol>
<p>We consider the optimization problem associated with fitting two-layers ReLU networks with respect to the squared loss, where labels are generated by a target network. We leverage the rich symmetry structure to analytically characterize the Hessian at various families of spurious minima in the natural regime where the number of inputs <span class="math inline">\(d\)</span> and the number of hidden neurons <span class="math inline">\(k\)</span> is finite. In particular, we prove that for <span class="math inline">\(d \geq k\)</span> standard Gaussian inputs: (a) of the <span class="math inline">\(d k\)</span> eigenvalues of the Hessian, <span class="math inline">\(d k-O(d)\)</span> concentrate near zero, (b) <span class="math inline">\(\Omega(d)\)</span> of the eigenvalues grow linearly with <span class="math inline">\(k\)</span>. Although this phenomenon of extremely skewed spectrum has been observed many times before, to our knowledge, this is the first time it has been established rigorously. Our analytic approach uses techniques, new to the field, from symmetry breaking and representation theory, and carries important implications for our ability to argue about statistical generalization through local curvature.</p>
<ol start="2" type="1">
<li><a href="https://arxiv.org/pdf/1711.10455.pdf" target="_blank" rel="noopener">Backprop as Functor: A compositional perspective on supervised learning</a></li>
</ol>
<p>Abstract-A supervised learning algorithm searches over a set of functions <span class="math inline">\(A \rightarrow B\)</span> parametrised by a space <span class="math inline">\(P\)</span> to find the best approximation to some ideal function <span class="math inline">\(f: A \rightarrow B .\)</span> It does this by taking examples <span class="math inline">\((a, f(a)) \in A \times B,\)</span> and updating the parameter according to some rule. We define a category where these update rules may be composed, and show that gradient descent-with respect to a fixed step size and an error function satisfying a certain property-defines a monoidal functor from a category of parametrised functions to this category of update rules. A key contribution is the notion of request function. This provides a structural perspective on backpropagation, giving a broad generalisation of neural networks and linking it with structures from bidirectional programming and open games.</p>
<h3 id="微分几何">3. 微分几何</h3>
<p>流形分布假设：比如手写数据，大多数情况下分布在一个流形上面。于是可以用微分几何 来研究输入到输出的关系。</p>
<p><a href="https://www.sciencedirect.com/science/article/pii/S2095809919302279" target="_blank" rel="noopener">A Geometric Understanding of Deep Learning</a></p>
<p>This work introduces an optimal transportation (OT) view of generative adversarial networks (GANs). Natural datasets have intrinsic patterns, which can be summarized as the manifold distribution principle: the distribution of a class of data is close to a low-dimensional manifold. GANs mainly accomplish two tasks: manifold learning and probability distribution transformation. The latter can be carried out using the classical OT method. From the OT perspective, the generator computes the OT map, while the discriminator computes the Wasserstein distance between the generated data distribution and the real data distribution; both can be reduced to a convex geometric optimization process. Furthermore, OT theory discovers the intrinsic collaborative—instead of competitive—relation between the generator and the discriminator, and the fundamental reason for mode collapse. We also propose a novel generative model, which uses an autoencoder (AE) for manifold learning and OT map for probability distribution transformation. This AE–OT model improves the theoretical rigor and transparency, as well as the computational stability and efficiency; in particular, it eliminates the mode collapse. The experimental results validate our hypothesis, and demonstrate the advantages of our proposed model.</p>
<h3 id="代数几何">4. 代数几何</h3>
<p>热带几何是代数几何的一种变体。ReLU是在0和1处取大，取大和加减法定义了热带几何的一些运算，通过运算可以定义一些多项式。代数几何 是一种研究多项式的几何。</p>
<p><a href="https://arxiv.org/abs/1805.07091" target="_blank" rel="noopener">Tropical geometry of deep neural networks</a></p>
<p>We establish, for the first time, connections between feedforward neural networks with ReLU activation and tropical geometry --- we show that the family of such neural networks is equivalent to the family of tropical rational maps. Among other things, we deduce that feedforward ReLU neural networks with one hidden layer can be characterized by zonotopes, which serve as building blocks for deeper networks; we relate decision boundaries of such neural networks to tropical hypersurfaces, a major object of study in tropical geometry; and we prove that linear regions of such neural networks correspond to vertices of polytopes associated with tropical rational functions. An insight from our tropical formulation is that a deeper network is exponentially more expressive than a shallow network.</p>
<h3 id="随机矩阵">5. 随机矩阵</h3>
<p>大型神经网络的权值比较接近随机分布。随机矩阵理论刻画神经网络的谱的性质。</p>
<ol type="1">
<li>Louart, <span class="math inline">\(C _{.}\)</span>, Liao, <span class="math inline">\(Z\)</span>. and Couillet, R. (2018). A random matrix approach to neural networks. The Annals of Applied Probability, <span class="math inline">\(28(2), 1190-1248 .\)</span></li>
<li>Pennington, J. and Worah, P. (2017). Nonlinear random matrix theory for deep learning. NIPS.</li>
</ol>
<h3 id="最优传输">6. 最优传输</h3>
<p>很适合GAN。最优传输</p>
<p>Peyré, G. and Cuturi, M. (2019). Computational optimal transport: With applications to data science. Foundations and Trends in Machine Learning, <span class="math inline">\(11(5-6), 355-607 .\)</span></p>
<h3 id="动力系统与随机分析">7. 动力系统与随机分析</h3>
<p>Haber, E. and Ruthotto, L. (2017). Stable architectures for deep neural networks. Inverse Problems, 34(1) , 014004</p>
<p>Raginsky, M., Rakhlin, A. and Telgarsky, M. (2017). Non-convex learning via stochastic gradient Langevin dynamics: A nonasymptotic analysis. COLT.</p>
<h3 id="统计物理与非线性科学">8. 统计物理与非线性科学</h3>
<p>Mei, S., Montanari, A. and Nguyen, P.-M. (2018). <a href="https://arxiv.org/pdf/1804.06561.pdf" target="_blank" rel="noopener">A mean field view of the landscape of two-layer neural networks</a>. <span class="math inline">\(P N A S, 115(33), E 7665-E 7671 .\)</span> Simsekli, U., Sener, O., Deligiannidis, G. and Erdogdu, M. A. (2020). Hausdorff dimension, heavy tails, and generalization in neural networks. NeurlPS.</p>
<h3 id="信息论">9. 信息论</h3>
<p>Shwartz-Ziv, R. and Tishby, N. (2017) . Opening the black box of deep neural networks via information. arXiv:1703.00810.</p>
<p><span class="math inline">\(Y u, Y_{.,}\)</span> Chan, <span class="math inline">\(K . H . R .\)</span> You, <span class="math inline">\(C .\)</span> Song, <span class="math inline">\(C .\)</span> and <span class="math inline">\(M a, Y .(2020) .\)</span> Learning diverse and discriminative representations via the principle of maximal coding rate reduction. NeurlPS.</p>
<h3 id="博弈论">10. 博弈论</h3>
<p>Lundberg, S. <span class="math inline">\(M .\)</span> and Lee, S.-1. ( 2017 ). A unified approach to interpreting model predictions. NIPS.</p>

            </article>
            <hr>
            <div>
              <div class="post-metas mb-3">
                
                  <div class="post-meta mr-3">
                    <i class="iconfont icon-category"></i>
                    
                      <a class="hover-with-bg" href="/categories/Machine-learning/">Machine learning</a>
                    
                  </div>
                
                
                  <div class="post-meta">
                    <i class="iconfont icon-tags"></i>
                    
                      <a class="hover-with-bg" href="/tags/Machine-learning/">Machine learning</a>
                    
                  </div>
                
              </div>
              
                <p class="note note-warning">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-sa/4.0/deed.zh" target="_blank" rel="nofollow noopener noopener">CC BY-SA 4.0 协议</a> ，转载请注明出处！</p>
              
              
                <div class="post-prevnext row">
                  <div class="post-prev col-6">
                    
                    
                      <a href="/2021/02/05/CMP_12_HeavyFermions03_SC/">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">重费米子超导</span>
                        <span class="visible-mobile">Previous</span>
                      </a>
                    
                  </div>
                  <div class="post-next col-6">
                    
                    
                      <a href="/2021/02/03/ML_06_explain_review/">
                        <span class="hidden-mobile">神经网络可解释性综述</span>
                        <span class="visible-mobile">Next</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </div>
                </div>
              
            </div>

            
          </div>
        </div>
      </div>
    </div>
    
      <div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn">
        <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;TOC</p>
  <div id="tocbot"></div>
</div>


      </div>
    
  </div>
</div>

<!-- Custom -->


    
  </main>

  
    <a id="scroll-top-button" href="#" role="button">
      <i class="iconfont icon-arrowup" aria-hidden="true"></i>
    </a>
  

  
    <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">Search</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v"
                 for="local-search-input">keyword</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>
  

  

  

  <footer class="mt-5">
  <div class="text-center py-3">
    <div>
      <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a>
      <i class="iconfont icon-love"></i>
      <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener">
        <span>Fluid</span></a>
    </div>
    

    

    
  </div>
</footer>

<!-- SCRIPTS -->
<script  src="https://cdn.staticfile.org/jquery/3.4.1/jquery.min.js" ></script>
<script  src="https://cdn.staticfile.org/twitter-bootstrap/4.4.1/js/bootstrap.min.js" ></script>
<script  src="/js/debouncer.js" ></script>
<script  src="/js/main.js" ></script>

<!-- Plugins -->


  
    <script  src="/js/lazyload.js" ></script>
  



  <script defer src="https://cdn.staticfile.org/clipboard.js/2.0.6/clipboard.min.js" ></script>
  <script  src="/js/clipboard-use.js" ></script>







  <script  src="https://cdn.staticfile.org/tocbot/4.11.1/tocbot.min.js" ></script>
  <script>
    $(document).ready(function () {
      var boardCtn = $('#board-ctn');
      var boardTop = boardCtn.offset().top;

      tocbot.init({
        tocSelector: '#tocbot',
        contentSelector: 'article.markdown-body',
        headingSelector: 'h1,h2,h3,h4,h5,h6',
        linkClass: 'tocbot-link',
        activeLinkClass: 'tocbot-active-link',
        listClass: 'tocbot-list',
        isCollapsedClass: 'tocbot-is-collapsed',
        collapsibleClass: 'tocbot-is-collapsible',
        collapseDepth: 1,
        scrollSmooth: true,
        headingsOffset: -boardTop
      });
      if ($('.toc-list-item').length > 0) {
        $('#toc').css('visibility', 'visible');
      }
    });
  </script>



  <script  src="https://cdn.staticfile.org/typed.js/2.0.11/typed.min.js" ></script>
  <script>
    var typed = new Typed('#subtitle', {
      strings: [
        '  ',
        "人工智能的新数学&nbsp;",
      ],
      cursorChar: "_",
      typeSpeed: 70,
      loop: false,
    });
    typed.stop();
    $(document).ready(function () {
      $(".typed-cursor").addClass("h2");
      typed.start();
    });
  </script>



  <script  src="https://cdn.staticfile.org/anchor-js/4.2.2/anchor.min.js" ></script>
  <script>
    anchors.options = {
      placement: "right",
      visible: "hover",
      
    };
    var el = "h1,h2,h3,h4,h5,h6".split(",");
    var res = [];
    for (item of el) {
      res.push(".markdown-body > " + item)
    }
    anchors.add(res.join(", "))
  </script>



  <script  src="/js/local-search.js" ></script>
  <script>
    var path = "/local-search.xml";
    var inputArea = document.querySelector("#local-search-input");
    inputArea.onclick = function () {
      searchFunc(path, 'local-search-input', 'local-search-result');
      this.onclick = null
    }
  </script>



  <script  src="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.js" ></script>
  <link  rel="stylesheet" href="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.css" />

  <script>
    $('#post img:not(.no-zoom img, img[no-zoom]), img[zoom]').each(
      function () {
        var element = document.createElement('a');
        $(element).attr('data-fancybox', 'images');
        $(element).attr('href', $(this).attr('src'));
        $(this).wrap(element);
      }
    );
  </script>





  

  
    <!-- MathJax -->
    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']]
        },
        options: {
          renderActions: {
            findScript: [10, doc => {
              document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
                const display = !!node.type.match(/; *mode=display/);
                const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
                const text = document.createTextNode('');
                node.parentNode.replaceChild(text, node);
                math.start = { node: text, delim: '', n: 0 };
                math.end = { node: text, delim: '', n: 0 };
                doc.math.push(math);
              });
            }, '', false],
            insertedScript: [200, () => {
              document.querySelectorAll('mjx-container').forEach(node => {
                let target = node.parentNode;
                if (target.nodeName.toLowerCase() === 'li') {
                  target.parentNode.classList.add('has-jax');
                }
              });
            }, '', false]
          }
        }
      };
    </script>

    <script async src="https://cdn.staticfile.org/mathjax/3.0.5/es5/tex-svg.js" ></script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config("");
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->

  
















</body>
</html>
